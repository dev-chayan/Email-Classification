{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "# import nltk\n",
    "from wordcloud import WordCloud, STOPWORDS \n",
    "import matplotlib.pyplot as plt \n",
    "# from nltk import PorterStemmer\n",
    "# nltk.download(\"wordnet\")\n",
    "# from nltk import WordNetLemmatizer\n",
    "import spacy\n",
    "stopwords = set(STOPWORDS) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tower Name</th>\n",
       "      <th>Application Name</th>\n",
       "      <th>Email Subject</th>\n",
       "      <th>Flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Core Pharmacy</td>\n",
       "      <td>PharmRDS-Accredo RealTime Messages</td>\n",
       "      <td>Production - Accredo Real Time Order Process S...</td>\n",
       "      <td>Actionable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Core Pharmacy</td>\n",
       "      <td>IVR - Web Service</td>\n",
       "      <td>Splunk Alert: SO IVR - Pharmacy Migration Coor...</td>\n",
       "      <td>Actionable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Core Pharmacy</td>\n",
       "      <td>ISAM- Web Service</td>\n",
       "      <td>Splunk Alert: ISAM - Slowness</td>\n",
       "      <td>Actionable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Core Pharmacy</td>\n",
       "      <td>Migration Co-Ordinaor</td>\n",
       "      <td>Splunk Alert: Migration_Coordinator_500 Clone</td>\n",
       "      <td>Actionable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Core Pharmacy</td>\n",
       "      <td>Claim Realm - Web Service</td>\n",
       "      <td>Splunk Alert: Claim Realm Service - Slowness A...</td>\n",
       "      <td>Actionable</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Tower Name                    Application Name  \\\n",
       "0  Core Pharmacy  PharmRDS-Accredo RealTime Messages   \n",
       "1  Core Pharmacy                   IVR - Web Service   \n",
       "2  Core Pharmacy                   ISAM- Web Service   \n",
       "3  Core Pharmacy               Migration Co-Ordinaor   \n",
       "4  Core Pharmacy           Claim Realm - Web Service   \n",
       "\n",
       "                                       Email Subject        Flag  \n",
       "0  Production - Accredo Real Time Order Process S...  Actionable  \n",
       "1  Splunk Alert: SO IVR - Pharmacy Migration Coor...  Actionable  \n",
       "2                      Splunk Alert: ISAM - Slowness  Actionable  \n",
       "3      Splunk Alert: Migration_Coordinator_500 Clone  Actionable  \n",
       "4  Splunk Alert: Claim Realm Service - Slowness A...  Actionable  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel(\"Email_Classificaion.xlsx\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tower Name          0\n",
       "Application Name    0\n",
       "Email Subject       0\n",
       "Flag                7\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tower Name</th>\n",
       "      <th>Application Name</th>\n",
       "      <th>Email Subject</th>\n",
       "      <th>Flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Core Pharmacy</td>\n",
       "      <td>PharmRDS-Accredo RealTime Messages</td>\n",
       "      <td>Production - Accredo Real Time Order Process S...</td>\n",
       "      <td>Actionable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Core Pharmacy</td>\n",
       "      <td>IVR - Web Service</td>\n",
       "      <td>Splunk Alert: SO IVR - Pharmacy Migration Coor...</td>\n",
       "      <td>Actionable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Core Pharmacy</td>\n",
       "      <td>ISAM- Web Service</td>\n",
       "      <td>Splunk Alert: ISAM - Slowness</td>\n",
       "      <td>Actionable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Core Pharmacy</td>\n",
       "      <td>Migration Co-Ordinaor</td>\n",
       "      <td>Splunk Alert: Migration_Coordinator_500 Clone</td>\n",
       "      <td>Actionable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Core Pharmacy</td>\n",
       "      <td>Claim Realm - Web Service</td>\n",
       "      <td>Splunk Alert: Claim Realm Service - Slowness A...</td>\n",
       "      <td>Actionable</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Tower Name                    Application Name  \\\n",
       "0  Core Pharmacy  PharmRDS-Accredo RealTime Messages   \n",
       "1  Core Pharmacy                   IVR - Web Service   \n",
       "2  Core Pharmacy                   ISAM- Web Service   \n",
       "3  Core Pharmacy               Migration Co-Ordinaor   \n",
       "4  Core Pharmacy           Claim Realm - Web Service   \n",
       "\n",
       "                                       Email Subject        Flag  \n",
       "0  Production - Accredo Real Time Order Process S...  Actionable  \n",
       "1  Splunk Alert: SO IVR - Pharmacy Migration Coor...  Actionable  \n",
       "2                      Splunk Alert: ISAM - Slowness  Actionable  \n",
       "3      Splunk Alert: Migration_Coordinator_500 Clone  Actionable  \n",
       "4  Splunk Alert: Claim Realm Service - Slowness A...  Actionable  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ger rid of na values in Flag\n",
    "data = data[~data['Flag'].isna()]\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Actionable        48\n",
       "Non Actionable    18\n",
       "Name: Flag, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Flag'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy['combined'] = data_copy.apply(lambda x : f\"{x[0]} {x[1]} {x[2]}\",axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tower Name</th>\n",
       "      <th>Application Name</th>\n",
       "      <th>Email Subject</th>\n",
       "      <th>Flag</th>\n",
       "      <th>combined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Core Pharmacy</td>\n",
       "      <td>PharmRDS-Accredo RealTime Messages</td>\n",
       "      <td>Production - Accredo Real Time Order Process S...</td>\n",
       "      <td>Actionable</td>\n",
       "      <td>Core Pharmacy PharmRDS-Accredo RealTime Messag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Core Pharmacy</td>\n",
       "      <td>IVR - Web Service</td>\n",
       "      <td>Splunk Alert: SO IVR - Pharmacy Migration Coor...</td>\n",
       "      <td>Actionable</td>\n",
       "      <td>Core Pharmacy IVR - Web Service Splunk Alert: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Core Pharmacy</td>\n",
       "      <td>ISAM- Web Service</td>\n",
       "      <td>Splunk Alert: ISAM - Slowness</td>\n",
       "      <td>Actionable</td>\n",
       "      <td>Core Pharmacy ISAM- Web Service Splunk Alert: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Core Pharmacy</td>\n",
       "      <td>Migration Co-Ordinaor</td>\n",
       "      <td>Splunk Alert: Migration_Coordinator_500 Clone</td>\n",
       "      <td>Actionable</td>\n",
       "      <td>Core Pharmacy Migration Co-Ordinaor Splunk Ale...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Core Pharmacy</td>\n",
       "      <td>Claim Realm - Web Service</td>\n",
       "      <td>Splunk Alert: Claim Realm Service - Slowness A...</td>\n",
       "      <td>Actionable</td>\n",
       "      <td>Core Pharmacy Claim Realm - Web Service Splunk...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Tower Name                    Application Name  \\\n",
       "0  Core Pharmacy  PharmRDS-Accredo RealTime Messages   \n",
       "1  Core Pharmacy                   IVR - Web Service   \n",
       "2  Core Pharmacy                   ISAM- Web Service   \n",
       "3  Core Pharmacy               Migration Co-Ordinaor   \n",
       "4  Core Pharmacy           Claim Realm - Web Service   \n",
       "\n",
       "                                       Email Subject        Flag  \\\n",
       "0  Production - Accredo Real Time Order Process S...  Actionable   \n",
       "1  Splunk Alert: SO IVR - Pharmacy Migration Coor...  Actionable   \n",
       "2                      Splunk Alert: ISAM - Slowness  Actionable   \n",
       "3      Splunk Alert: Migration_Coordinator_500 Clone  Actionable   \n",
       "4  Splunk Alert: Claim Realm Service - Slowness A...  Actionable   \n",
       "\n",
       "                                            combined  \n",
       "0  Core Pharmacy PharmRDS-Accredo RealTime Messag...  \n",
       "1  Core Pharmacy IVR - Web Service Splunk Alert: ...  \n",
       "2  Core Pharmacy ISAM- Web Service Splunk Alert: ...  \n",
       "3  Core Pharmacy Migration Co-Ordinaor Splunk Ale...  \n",
       "4  Core Pharmacy Claim Realm - Web Service Splunk...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_copy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def Preprocessing_stemming(df,column_name):\n",
    "#     # Email Subject column\n",
    "#     df[column_name] = df[column_name].apply(lambda x: re.sub('[^A-Za-z]',\" \",x))\n",
    "#     df[column_name] = df[column_name].replace([\" \",\"  \",\"   \"],\" \",regex = True)\n",
    "#     stopwords = set(STOPWORDS) \n",
    "#     stemmer = PorterStemmer()\n",
    "#     df[column_name] = df[column_name].apply(lambda x : x.lower())\n",
    "#     df[column_name] = df[column_name].apply(lambda x : \" \".join(word for word in x if len(word) > 2))\n",
    "#     df[column_name] = df[column_name].apply(lambda x : \" \".join([word for word in x.split() if word not in stopwords]))\n",
    "#     df[column_name] = df[column_name].apply(lambda x : stemmer.stem(x)) \n",
    "#     return df[column_name]\n",
    "\n",
    "\n",
    "# def Preprocessing_lemmatization(df,column_name):\n",
    "#     # Email Subject column\n",
    "#     df[column_name] = df[column_name].apply(lambda x: re.sub('[^A-Za-z]',\" \",x))\n",
    "#     df[column_name] = df[column_name].replace([\" \",\"  \",\"   \"],\" \",regex = True)\n",
    "#     stopwords = set(STOPWORDS) \n",
    "#     lemmatizer = WordNetLemmatizer()\n",
    "#     df[column_name] = df[column_name].apply(lambda x : x.lower())\n",
    "#     df[column_name] = df[column_name].apply(lambda x : \" \".join(word for word in x if len(word) > 2))\n",
    "#     df[column_name] = df[column_name].apply(lambda x : \" \".join([word for word in x.split() if word not in stopwords]))\n",
    "#     df[column_name] = df[column_name].apply(lambda x : lemmatizer.lemmatize(x)) \n",
    "#     return df[column_name]\n",
    "\n",
    "\n",
    "def Preprocessing_lemmatization_spacy(df,column_name):\n",
    "    # Email Subject column\n",
    "    df[column_name] = df[column_name].apply(lambda x: re.sub('[^A-Za-z]',\" \",x))\n",
    "    _RE_COMBINE_WHITESPACE = re.compile(r\"\\s+\")\n",
    "    df[column_name] = df[column_name].apply(lambda x: _RE_COMBINE_WHITESPACE.sub(\" \",x).strip())\n",
    "    stopwords = set(STOPWORDS) \n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    df[column_name] = df[column_name].apply(lambda x : x.lower())\n",
    "    df[column_name] = df[column_name].apply(lambda x : \" \".join(word for word in x.split() if len(word) > 2))\n",
    "    df[column_name] = df[column_name].apply(lambda x : \" \".join([word for word in x.split() if word not in stopwords]))\n",
    "    df[column_name] = df[column_name].apply(lambda x : \" \".join(token.lemma_ for token in nlp(x))) \n",
    "    return df[column_name]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tower Name</th>\n",
       "      <th>Application Name</th>\n",
       "      <th>Email Subject</th>\n",
       "      <th>Flag</th>\n",
       "      <th>combined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Core Pharmacy</td>\n",
       "      <td>PharmRDS-Accredo RealTime Messages</td>\n",
       "      <td>Production - Accredo Real Time Order Process S...</td>\n",
       "      <td>Actionable</td>\n",
       "      <td>core pharmacy pharmrd accredo realtime message...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Core Pharmacy</td>\n",
       "      <td>IVR - Web Service</td>\n",
       "      <td>Splunk Alert: SO IVR - Pharmacy Migration Coor...</td>\n",
       "      <td>Actionable</td>\n",
       "      <td>core pharmacy ivr web service splunk alert ivr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Core Pharmacy</td>\n",
       "      <td>ISAM- Web Service</td>\n",
       "      <td>Splunk Alert: ISAM - Slowness</td>\n",
       "      <td>Actionable</td>\n",
       "      <td>core pharmacy isam web service splunk alert is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Core Pharmacy</td>\n",
       "      <td>Migration Co-Ordinaor</td>\n",
       "      <td>Splunk Alert: Migration_Coordinator_500 Clone</td>\n",
       "      <td>Actionable</td>\n",
       "      <td>core pharmacy migration ordinaor splunk alert ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Core Pharmacy</td>\n",
       "      <td>Claim Realm - Web Service</td>\n",
       "      <td>Splunk Alert: Claim Realm Service - Slowness A...</td>\n",
       "      <td>Actionable</td>\n",
       "      <td>core pharmacy claim realm web service splunk a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Tower Name                    Application Name  \\\n",
       "0  Core Pharmacy  PharmRDS-Accredo RealTime Messages   \n",
       "1  Core Pharmacy                   IVR - Web Service   \n",
       "2  Core Pharmacy                   ISAM- Web Service   \n",
       "3  Core Pharmacy               Migration Co-Ordinaor   \n",
       "4  Core Pharmacy           Claim Realm - Web Service   \n",
       "\n",
       "                                       Email Subject        Flag  \\\n",
       "0  Production - Accredo Real Time Order Process S...  Actionable   \n",
       "1  Splunk Alert: SO IVR - Pharmacy Migration Coor...  Actionable   \n",
       "2                      Splunk Alert: ISAM - Slowness  Actionable   \n",
       "3      Splunk Alert: Migration_Coordinator_500 Clone  Actionable   \n",
       "4  Splunk Alert: Claim Realm Service - Slowness A...  Actionable   \n",
       "\n",
       "                                            combined  \n",
       "0  core pharmacy pharmrd accredo realtime message...  \n",
       "1  core pharmacy ivr web service splunk alert ivr...  \n",
       "2  core pharmacy isam web service splunk alert is...  \n",
       "3  core pharmacy migration ordinaor splunk alert ...  \n",
       "4  core pharmacy claim realm web service splunk a...  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_copy[\"combined\"] = Preprocessing_lemmatization_spacy(data_copy, \"combined\")\n",
    "data_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_copy[\"combined\"]\n",
    "y = data_copy[\"Flag\"].map({\"Actionable\" : 0, \"Non Actionable\" : 1})\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.40, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'smart_open' has no attribute 'local_file'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-8e545f4a15ad>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_extraction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m pipeline = Pipeline([\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\gensim\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \"\"\"\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mparsing\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorpora\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmatutils\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minterfaces\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msimilarities\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msummarization\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mutils\u001b[0m  \u001b[1;31m# noqa:F401\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\gensim\\parsing\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mporter\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPorterStemmer\u001b[0m  \u001b[1;31m# noqa:F401\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m from .preprocessing import (remove_stopwords, strip_punctuation, strip_punctuation2,  # noqa:F401\n\u001b[0m\u001b[0;32m      5\u001b[0m                             \u001b[0mstrip_tags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrip_short\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrip_numeric\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m                             \u001b[0mstrip_non_alphanum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrip_multiple_whitespaces\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\gensim\\parsing\\preprocessing.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparsing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mporter\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPorterStemmer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\gensim\\utils.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmoves\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msmart_open\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmultiprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcpu_count\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\smart_open\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msmart_open\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mversion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0msmart_open_lib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparse_uri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msmart_open\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mregister_compressor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0ms3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0miter_bucket\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0ms3_iter_bucket\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\smart_open\\smart_open_lib.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msmart_open\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcompression\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msmart_open\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdoctools\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msmart_open\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtransport\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msmart_open\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\smart_open\\doctools.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcompression\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtransport\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[0mPLACEHOLDER\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'    smart_open/doctools.py magic goes here'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\smart_open\\transport.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mNO_SCHEME\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[0m_REGISTRY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mNO_SCHEME\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0msmart_open\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlocal_file\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'smart_open' has no attribute 'local_file'"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "import gensim\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('rf_clf', RandomForestClassifier()),\n",
    "])\n",
    "\n",
    "params = {\"tfidf__ngram_range\" : [(1,2),(1,1)],\n",
    "         \"tfidf__max_df\" : [4,5,6,7,8],\n",
    "         \"tfidf__min_df\" : [1,2,3],\n",
    "         \"tfidf__max_features\" : [50,100,150,200],\n",
    "         \"rf_clf__n_estimators\" : [100,200,400],\n",
    "         \"rf_clf__max_depth\": [2,3,4],\n",
    "         \"rf_clf__min_samples_split\" : [2,3,4,5]}\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid_search = GridSearchCV(pipeline,param_grid= params, n_jobs=-1, verbose=1)\n",
    "\n",
    "print(\"Performing grid search...\")\n",
    "print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "print(\"parameters:\")\n",
    "print(params)\n",
    "grid_search.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_estimator_.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('tfidf', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=8, max_features=150, min_df=3,\n",
       "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "  ...obs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_rf = grid_search.best_estimator_\n",
    "best_rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------Training Result Xgboost--------------- \n",
      " \n",
      "\n",
      "[[26  1]\n",
      " [ 8  4]]\n",
      "accuracy --  0.7692307692307693\n",
      "precision_score --  0.8\n",
      "recall_score --  0.3333333333333333\n",
      "f1_score --  0.47058823529411764\n",
      "classification report --- \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.96      0.85        27\n",
      "           1       0.80      0.33      0.47        12\n",
      "\n",
      "   micro avg       0.77      0.77      0.77        39\n",
      "   macro avg       0.78      0.65      0.66        39\n",
      "weighted avg       0.78      0.77      0.73        39\n",
      "\n",
      "---------------Testing Result Xgboost--------------- \n",
      " \n",
      "\n",
      "[[18  3]\n",
      " [ 6  0]]\n",
      "accuracy --  0.6666666666666666\n",
      "precision_score --  0.0\n",
      "recall_score --  0.0\n",
      "f1_score --  0.0\n",
      "classification report --- \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.86      0.80        21\n",
      "           1       0.00      0.00      0.00         6\n",
      "\n",
      "   micro avg       0.67      0.67      0.67        27\n",
      "   macro avg       0.38      0.43      0.40        27\n",
      "weighted avg       0.58      0.67      0.62        27\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## prediction\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score,confusion_matrix,classification_report\n",
    "\n",
    "prediction_rf_train = best_rf.predict(X_train)\n",
    "\n",
    "print(\"---------------Training Result random forest--------------- \\n \\n\")\n",
    "print(confusion_matrix(y_train,prediction_rf_train))\n",
    "print(\"accuracy -- \" , accuracy_score(y_train,prediction_rf_train))\n",
    "print(\"precision_score -- \" , precision_score(y_train,prediction_rf_train))\n",
    "print(\"recall_score -- \" , recall_score(y_train,prediction_rf_train))\n",
    "print(\"f1_score -- \" , f1_score(y_train,prediction_rf_train))\n",
    "print(\"classification report --- \\n\",classification_report(y_train,prediction_rf_train))\n",
    "\n",
    "prediction_rf_test = best_rf.predict(X_test)\n",
    "\n",
    "print(\"---------------Testing Result random forest--------------- \\n \\n\")\n",
    "print(confusion_matrix(y_test,prediction_rf_test))\n",
    "print(\"accuracy -- \" , accuracy_score(y_test,prediction_rf_test))\n",
    "print(\"precision_score -- \" , precision_score(y_test,prediction_rf_test))\n",
    "print(\"recall_score -- \" , recall_score(y_test,prediction_rf_test))\n",
    "print(\"f1_score -- \" , f1_score(y_test,prediction_rf_test))\n",
    "print(\"classification report --- \\n\",classification_report(y_test,prediction_rf_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TFIDF with RF not using pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### First"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39, 100)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(use_idf = True, ngram_range = (1,1),max_df = 15,min_df = 1,max_features = 100,norm= 'l2')\n",
    "train_data = vectorizer.fit_transform(X_train)\n",
    "test_data = vectorizer.transform(X_test)\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Dump the file\n",
    "pickle.dump(vectorizer, open(\"tfidf.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dental': 33,\n",
       " 'warning': 93,\n",
       " 'abort': 1,\n",
       " 'attn': 8,\n",
       " 'home': 41,\n",
       " 'delivery': 32,\n",
       " 'team': 86,\n",
       " 'fairfax': 39,\n",
       " 'splunk': 81,\n",
       " 'alert': 3,\n",
       " 'cache': 15,\n",
       " 'file': 40,\n",
       " 'exception': 37,\n",
       " 'blockers': 13,\n",
       " 'webprd': 96,\n",
       " 'pdm': 57,\n",
       " 'subject': 84,\n",
       " 'contain': 28,\n",
       " 'pricing': 64,\n",
       " 'prd': 63,\n",
       " 'xrx': 99,\n",
       " 'application': 7,\n",
       " 'open': 53,\n",
       " 'problem': 65,\n",
       " 'failure': 38,\n",
       " 'rate': 69,\n",
       " 'increase': 42,\n",
       " 'web': 95,\n",
       " 'service': 77,\n",
       " 'chc': 19,\n",
       " 'prod': 67,\n",
       " 'chdpxrxtransactionservicewshpv': 22,\n",
       " 'log': 48,\n",
       " 'update': 91,\n",
       " 'last': 45,\n",
       " 'chdpxrxtransacionservicewshttpv': 21,\n",
       " 'mailrx': 49,\n",
       " 'router': 75,\n",
       " 'miss': 50,\n",
       " 'pdf': 56,\n",
       " 'report': 72,\n",
       " 'system': 85,\n",
       " 'unavailable': 90,\n",
       " 'wdc': 94,\n",
       " 'dna': 34,\n",
       " 'rds': 70,\n",
       " 'word': 98,\n",
       " 'ohip': 52,\n",
       " 'welcome': 97,\n",
       " 'clinicla': 26,\n",
       " 'cmg': 27,\n",
       " 'allscripts': 5,\n",
       " 'critical': 30,\n",
       " 'ciwinp': 24,\n",
       " 'lgenl': 46,\n",
       " 'drive': 35,\n",
       " 'space': 80,\n",
       " 'available': 10,\n",
       " 'apm': 6,\n",
       " 'chdp': 20,\n",
       " 'qdepth': 68,\n",
       " 'state': 83,\n",
       " 'request': 73,\n",
       " 'core': 29,\n",
       " 'pharmacy': 59,\n",
       " 'ivr': 44,\n",
       " 'error': 36,\n",
       " 'authentication': 9,\n",
       " 'order': 54,\n",
       " 'isam': 43,\n",
       " 'slowness': 79,\n",
       " 'ciwsqlxp': 25,\n",
       " 'lmsdb': 47,\n",
       " 'back': 11,\n",
       " 'database': 31,\n",
       " 'cerner': 18,\n",
       " 'celvr': 17,\n",
       " 'port': 62,\n",
       " 'warn': 92,\n",
       " 'payment': 55,\n",
       " 'spreadsheet': 82,\n",
       " 'batch': 12,\n",
       " 'abend': 0,\n",
       " 'ticket': 88,\n",
       " 'techrx': 87,\n",
       " 'size': 78,\n",
       " 'cauth': 16,\n",
       " 'please': 61,\n",
       " 'check': 23,\n",
       " 'reach': 71,\n",
       " 'business': 14,\n",
       " 'require': 74,\n",
       " 'allscript': 4,\n",
       " 'perfmon': 58,\n",
       " 'time': 89,\n",
       " 'pharmrd': 60,\n",
       " 'nrt': 51,\n",
       " 'process': 66,\n",
       " 'send': 76,\n",
       " 'action': 2}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=3, max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=2, min_samples_split=3,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=150, n_jobs=None,\n",
       "            oob_score=False, random_state=10, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_model = RandomForestClassifier(max_depth = 3,\n",
    "                                 max_features = None,\n",
    "                                 n_estimators = 150,\n",
    "                                 min_samples_split = 3,\n",
    "                                 min_samples_leaf = 2,\n",
    "                                 random_state = 10)\n",
    "rf_model.fit(train_data,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------Training Result random forest--------------- \n",
      " \n",
      "\n",
      "[[25  2]\n",
      " [ 0 12]]\n",
      "accuracy --  0.9487179487179487\n",
      "precision_score --  0.8571428571428571\n",
      "recall_score --  1.0\n",
      "f1_score --  0.923076923076923\n",
      "classification report --- \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96        27\n",
      "           1       0.86      1.00      0.92        12\n",
      "\n",
      "   micro avg       0.95      0.95      0.95        39\n",
      "   macro avg       0.93      0.96      0.94        39\n",
      "weighted avg       0.96      0.95      0.95        39\n",
      "\n",
      "---------------Testing Result random forest--------------- \n",
      " \n",
      "\n",
      "[[20  1]\n",
      " [ 1  5]]\n",
      "accuracy --  0.9259259259259259\n",
      "precision_score --  0.8333333333333334\n",
      "recall_score --  0.8333333333333334\n",
      "f1_score --  0.8333333333333334\n",
      "classification report --- \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95        21\n",
      "           1       0.83      0.83      0.83         6\n",
      "\n",
      "   micro avg       0.93      0.93      0.93        27\n",
      "   macro avg       0.89      0.89      0.89        27\n",
      "weighted avg       0.93      0.93      0.93        27\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## prediction\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score,confusion_matrix,classification_report\n",
    "\n",
    "prediction_rf_train = rf_model.predict(train_data)\n",
    "\n",
    "print(\"---------------Training Result random forest--------------- \\n \\n\")\n",
    "print(confusion_matrix(y_train,prediction_rf_train))\n",
    "print(\"accuracy -- \" , accuracy_score(y_train,prediction_rf_train))\n",
    "print(\"precision_score -- \" , precision_score(y_train,prediction_rf_train))\n",
    "print(\"recall_score -- \" , recall_score(y_train,prediction_rf_train))\n",
    "print(\"f1_score -- \" , f1_score(y_train,prediction_rf_train))\n",
    "print(\"classification report --- \\n\",classification_report(y_train,prediction_rf_train))\n",
    "\n",
    "prediction_rf_test = rf_model.predict(test_data)\n",
    "\n",
    "print(\"---------------Testing Result random forest--------------- \\n \\n\")\n",
    "print(confusion_matrix(y_test,prediction_rf_test))\n",
    "print(\"accuracy -- \" , accuracy_score(y_test,prediction_rf_test))\n",
    "print(\"precision_score -- \" , precision_score(y_test,prediction_rf_test))\n",
    "print(\"recall_score -- \" , recall_score(y_test,prediction_rf_test))\n",
    "print(\"f1_score -- \" , f1_score(y_test,prediction_rf_test))\n",
    "print(\"classification report --- \\n\",classification_report(y_test,prediction_rf_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes :- \n",
    "    - max_df = (13 - 18)\n",
    "    - min_df = (1 - 3)\n",
    "    - max_depth = (2 - 3)\n",
    "    - n_estimators = (100 - 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('random_forest_tfidf.pkl', 'wb') as f:\n",
    "    pickle.dump(rf_model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_phrase_in(phrase, text):\n",
    "        return re.search(r\"\\b{}\\b\".format(phrase), text, re.IGNORECASE) is not None\n",
    "\n",
    "\n",
    "def replace_bigram(sentence,dict_):\n",
    "    for bigram in dict_.keys():\n",
    "        if is_phrase_in(bigram,sentence):\n",
    "            sentence = sentence.replace(bigram,dict_[bigram])\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "doc = \" \".join(sent for sent in X_train)\n",
    "wordcloud = WordCloud(width = 800, height = 800, \n",
    "            background_color ='white', \n",
    "            stopwords = stopwords, \n",
    "            min_font_size = 20,\n",
    "            collocation_threshold = 18).generate(doc) \n",
    "\n",
    "top_50_words = list(wordcloud.words_.keys())[:90]\n",
    "# changing bigrams to unigrams in X_train for word_embedding\n",
    "\n",
    "change_dict = {}\n",
    "for word in top_50_words:\n",
    "    if len(word.split()) > 1:\n",
    "        change_dict[word] = word.replace(\" \",\"_\")\n",
    "\n",
    "top_50_words_changed = [change_dict[word] if word in list(change_dict.keys()) else word for word in top_50_words] \n",
    "\n",
    "\n",
    "X_train_copy = X_train.copy()\n",
    "X_train_copy = X_train_copy.apply(lambda x: replace_bigram(x,change_dict))\n",
    "\n",
    "# create tfidf based on these top_50_words\n",
    "tfidf_1 = TfidfVectorizer(vocabulary = top_50_words_changed)\n",
    "new_train_data = tfidf_1.fit_transform(X_train_copy)\n",
    "\n",
    "X_test_copy = X_test.copy()\n",
    "X_test_copy = X_test_copy.apply(lambda x: replace_bigram(x,change_dict))\n",
    "new_test_data = tfidf_1.transform(X_test_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=3, max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=2, min_samples_split=3,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=150, n_jobs=None,\n",
       "            oob_score=False, random_state=10, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier(max_depth = 3,\n",
    "                                 max_features = None,\n",
    "                                 n_estimators = 150,\n",
    "                                 min_samples_split = 3,\n",
    "                                 min_samples_leaf = 2,\n",
    "                                 random_state = 10)\n",
    "rf_model.fit(new_train_data,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------Training Result random forest--------------- \n",
      " \n",
      "\n",
      "[[25  2]\n",
      " [ 1 11]]\n",
      "accuracy --  0.9230769230769231\n",
      "precision_score --  0.8461538461538461\n",
      "recall_score --  0.9166666666666666\n",
      "f1_score --  0.8799999999999999\n",
      "classification report --- \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.94        27\n",
      "           1       0.85      0.92      0.88        12\n",
      "\n",
      "   micro avg       0.92      0.92      0.92        39\n",
      "   macro avg       0.90      0.92      0.91        39\n",
      "weighted avg       0.93      0.92      0.92        39\n",
      "\n",
      "---------------Testing Result random forest--------------- \n",
      " \n",
      "\n",
      "[[20  1]\n",
      " [ 2  4]]\n",
      "accuracy --  0.8888888888888888\n",
      "precision_score --  0.8\n",
      "recall_score --  0.6666666666666666\n",
      "f1_score --  0.7272727272727272\n",
      "classification report --- \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93        21\n",
      "           1       0.80      0.67      0.73         6\n",
      "\n",
      "   micro avg       0.89      0.89      0.89        27\n",
      "   macro avg       0.85      0.81      0.83        27\n",
      "weighted avg       0.88      0.89      0.89        27\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## prediction\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score,confusion_matrix,classification_report\n",
    "\n",
    "prediction_rf_train1 = rf_model.predict(new_train_data)\n",
    "\n",
    "print(\"---------------Training Result random forest--------------- \\n \\n\")\n",
    "print(confusion_matrix(y_train,prediction_rf_train1))\n",
    "print(\"accuracy -- \" , accuracy_score(y_train,prediction_rf_train1))\n",
    "print(\"precision_score -- \" , precision_score(y_train,prediction_rf_train1))\n",
    "print(\"recall_score -- \" , recall_score(y_train,prediction_rf_train1))\n",
    "print(\"f1_score -- \" , f1_score(y_train,prediction_rf_train1))\n",
    "print(\"classification report --- \\n\",classification_report(y_train,prediction_rf_train1))\n",
    "\n",
    "prediction_rf_test1 = rf_model.predict(new_test_data)\n",
    "\n",
    "print(\"---------------Testing Result random forest--------------- \\n \\n\")\n",
    "print(confusion_matrix(y_test,prediction_rf_test1))\n",
    "print(\"accuracy -- \" , accuracy_score(y_test,prediction_rf_test1))\n",
    "print(\"precision_score -- \" , precision_score(y_test,prediction_rf_test1))\n",
    "print(\"recall_score -- \" , recall_score(y_test,prediction_rf_test1))\n",
    "print(\"f1_score -- \" , f1_score(y_test,prediction_rf_test1))\n",
    "print(\"classification report --- \\n\",classification_report(y_test,prediction_rf_test1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Third"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy[\"Email Subject\"] = Preprocessing_lemmatization_spacy(data_copy, \"Email Subject\")\n",
    "X1 = data_copy[\"Email Subject\"]\n",
    "y1 = data_copy[\"Flag\"].map({\"Actionable\" : 0, \"Non Actionable\" : 1})\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X1, y1, test_size=0.40, random_state=42)\n",
    "training_index = X_train1.index\n",
    "testing_index = X_test1.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([66, 65, 57, 31, 51, 71, 15, 27, 26, 24, 54, 11, 32, 68, 53, 37, 29,\n",
       "            50, 56,  1, 21,  2, 60, 39, 35, 59, 23, 62, 10, 22, 18, 64, 38, 20,\n",
       "            67,  7, 49, 14, 58],\n",
       "           dtype='int64')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39, 29)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "import gensim\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "vectorizer = TfidfVectorizer(use_idf = True, ngram_range = (1,2),max_df = 10,min_df = 3,max_features = 200,norm= 'l2')\n",
    "train_data = vectorizer.fit_transform(X_train1)\n",
    "test_data = vectorizer.transform(X_test1)\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'warning': 24,\n",
       " 'splunk': 20,\n",
       " 'alert': 0,\n",
       " 'file': 6,\n",
       " 'splunk alert': 21,\n",
       " 'subject': 22,\n",
       " 'contain': 3,\n",
       " 'subject contain': 23,\n",
       " 'open': 11,\n",
       " 'problem': 13,\n",
       " 'failure': 4,\n",
       " 'rate': 16,\n",
       " 'increase': 7,\n",
       " 'web': 25,\n",
       " 'service': 18,\n",
       " 'chc': 1,\n",
       " 'xrx': 27,\n",
       " 'prod': 15,\n",
       " 'open problem': 12,\n",
       " 'problem failure': 14,\n",
       " 'failure rate': 5,\n",
       " 'rate increase': 17,\n",
       " 'increase web': 8,\n",
       " 'web service': 26,\n",
       " 'service chc': 19,\n",
       " 'chc xrx': 2,\n",
       " 'xrx prod': 28,\n",
       " 'log': 10,\n",
       " 'last': 9}"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build dataframe\n",
    "train_data = pd.DataFrame(train_data.toarray(),columns =vectorizer.vocabulary_,index = training_index)\n",
    "test_data = pd.DataFrame(test_data.toarray(),columns =vectorizer.vocabulary_,index = testing_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>warning</th>\n",
       "      <th>splunk</th>\n",
       "      <th>alert</th>\n",
       "      <th>file</th>\n",
       "      <th>splunk alert</th>\n",
       "      <th>subject</th>\n",
       "      <th>contain</th>\n",
       "      <th>subject contain</th>\n",
       "      <th>open</th>\n",
       "      <th>problem</th>\n",
       "      <th>...</th>\n",
       "      <th>problem failure</th>\n",
       "      <th>failure rate</th>\n",
       "      <th>rate increase</th>\n",
       "      <th>increase web</th>\n",
       "      <th>web service</th>\n",
       "      <th>service chc</th>\n",
       "      <th>chc xrx</th>\n",
       "      <th>xrx prod</th>\n",
       "      <th>log</th>\n",
       "      <th>last</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.430275</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.578357</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.490085</td>\n",
       "      <td>0.490085</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     warning  splunk  alert  file  splunk alert  subject   contain  \\\n",
       "66  0.000000     0.0    0.0   0.0           0.0      0.0  0.000000   \n",
       "65  0.000000     0.0    0.0   0.0           0.0      0.0  0.000000   \n",
       "57  0.000000     0.0    0.0   0.0           0.0      0.0  0.000000   \n",
       "31  0.430275     0.0    0.0   0.0           0.0      0.0  0.578357   \n",
       "51  0.000000     0.0    0.0   0.0           0.0      0.0  0.000000   \n",
       "\n",
       "    subject contain  open  problem  ...  problem failure  failure rate  \\\n",
       "66              0.0   0.0      0.0  ...              0.0      0.000000   \n",
       "65              0.0   0.0      0.0  ...              0.0      0.000000   \n",
       "57              0.0   0.0      0.0  ...              0.0      0.000000   \n",
       "31              0.0   0.0      0.0  ...              0.0      0.490085   \n",
       "51              0.0   0.0      0.0  ...              0.0      0.000000   \n",
       "\n",
       "    rate increase  increase web  web service  service chc  chc xrx  xrx prod  \\\n",
       "66       0.000000           0.0          0.0          1.0      0.0       0.0   \n",
       "65       0.000000           0.0          0.0          0.0      0.0       0.0   \n",
       "57       0.000000           0.0          0.0          0.0      0.0       0.0   \n",
       "31       0.490085           0.0          0.0          0.0      0.0       0.0   \n",
       "51       0.000000           0.0          0.0          0.0      0.0       0.0   \n",
       "\n",
       "    log  last  \n",
       "66  0.0   0.0  \n",
       "65  0.0   0.0  \n",
       "57  0.0   0.0  \n",
       "31  0.0   0.0  \n",
       "51  0.0   0.0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tower Name_Core Pharmacy</th>\n",
       "      <th>Tower Name_Coresol</th>\n",
       "      <th>Tower Name_DNA</th>\n",
       "      <th>Tower Name_Dental</th>\n",
       "      <th>Tower Name_Home Delivery Team</th>\n",
       "      <th>Application Name_AllScripts</th>\n",
       "      <th>Application Name_Cerner</th>\n",
       "      <th>Application Name_Claim Realm - Web Service</th>\n",
       "      <th>Application Name_Claims RDS</th>\n",
       "      <th>Application Name_DrugPricing - Web Service</th>\n",
       "      <th>...</th>\n",
       "      <th>Application Name_ODS</th>\n",
       "      <th>Application Name_PDA</th>\n",
       "      <th>Application Name_PDM</th>\n",
       "      <th>Application Name_PRDS</th>\n",
       "      <th>Application Name_PharmRDS-Accredo RealTime Messages</th>\n",
       "      <th>Application Name_PharmRDS-IIB Alert</th>\n",
       "      <th>Application Name_PharmRDS-NRT Alert</th>\n",
       "      <th>Application Name_SRWSQLXPW001.internal.cigna.com</th>\n",
       "      <th>Application Name_UC4</th>\n",
       "      <th>Application Name_xRx Application</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Tower Name_Core Pharmacy  Tower Name_Coresol  Tower Name_DNA  \\\n",
       "0                          1                   0               0   \n",
       "1                          1                   0               0   \n",
       "2                          1                   0               0   \n",
       "3                          1                   0               0   \n",
       "4                          1                   0               0   \n",
       "..                       ...                 ...             ...   \n",
       "68                         0                   0               1   \n",
       "69                         0                   1               0   \n",
       "70                         0                   0               1   \n",
       "71                         0                   1               0   \n",
       "72                         0                   1               0   \n",
       "\n",
       "    Tower Name_Dental  Tower Name_Home Delivery Team  \\\n",
       "0                   0                              0   \n",
       "1                   0                              0   \n",
       "2                   0                              0   \n",
       "3                   0                              0   \n",
       "4                   0                              0   \n",
       "..                ...                            ...   \n",
       "68                  0                              0   \n",
       "69                  0                              0   \n",
       "70                  0                              0   \n",
       "71                  0                              0   \n",
       "72                  0                              0   \n",
       "\n",
       "    Application Name_AllScripts  Application Name_Cerner  \\\n",
       "0                             0                        0   \n",
       "1                             0                        0   \n",
       "2                             0                        0   \n",
       "3                             0                        0   \n",
       "4                             0                        0   \n",
       "..                          ...                      ...   \n",
       "68                            0                        0   \n",
       "69                            0                        0   \n",
       "70                            0                        0   \n",
       "71                            0                        0   \n",
       "72                            0                        0   \n",
       "\n",
       "    Application Name_Claim Realm - Web Service  Application Name_Claims RDS  \\\n",
       "0                                            0                            0   \n",
       "1                                            0                            0   \n",
       "2                                            0                            0   \n",
       "3                                            0                            0   \n",
       "4                                            1                            0   \n",
       "..                                         ...                          ...   \n",
       "68                                           0                            1   \n",
       "69                                           0                            0   \n",
       "70                                           0                            0   \n",
       "71                                           0                            0   \n",
       "72                                           0                            0   \n",
       "\n",
       "    Application Name_DrugPricing - Web Service  ...  Application Name_ODS  \\\n",
       "0                                            0  ...                     0   \n",
       "1                                            0  ...                     0   \n",
       "2                                            0  ...                     0   \n",
       "3                                            0  ...                     0   \n",
       "4                                            0  ...                     0   \n",
       "..                                         ...  ...                   ...   \n",
       "68                                           0  ...                     0   \n",
       "69                                           0  ...                     0   \n",
       "70                                           0  ...                     1   \n",
       "71                                           0  ...                     0   \n",
       "72                                           0  ...                     0   \n",
       "\n",
       "    Application Name_PDA  Application Name_PDM  Application Name_PRDS  \\\n",
       "0                      0                     0                      0   \n",
       "1                      0                     0                      0   \n",
       "2                      0                     0                      0   \n",
       "3                      0                     0                      0   \n",
       "4                      0                     0                      0   \n",
       "..                   ...                   ...                    ...   \n",
       "68                     0                     0                      0   \n",
       "69                     0                     0                      0   \n",
       "70                     0                     0                      0   \n",
       "71                     0                     1                      0   \n",
       "72                     1                     0                      0   \n",
       "\n",
       "    Application Name_PharmRDS-Accredo RealTime Messages  \\\n",
       "0                                                   1     \n",
       "1                                                   0     \n",
       "2                                                   0     \n",
       "3                                                   0     \n",
       "4                                                   0     \n",
       "..                                                ...     \n",
       "68                                                  0     \n",
       "69                                                  0     \n",
       "70                                                  0     \n",
       "71                                                  0     \n",
       "72                                                  0     \n",
       "\n",
       "    Application Name_PharmRDS-IIB Alert  Application Name_PharmRDS-NRT Alert  \\\n",
       "0                                     0                                    0   \n",
       "1                                     0                                    0   \n",
       "2                                     0                                    0   \n",
       "3                                     0                                    0   \n",
       "4                                     0                                    0   \n",
       "..                                  ...                                  ...   \n",
       "68                                    0                                    0   \n",
       "69                                    0                                    0   \n",
       "70                                    0                                    0   \n",
       "71                                    0                                    0   \n",
       "72                                    0                                    0   \n",
       "\n",
       "    Application Name_SRWSQLXPW001.internal.cigna.com  Application Name_UC4  \\\n",
       "0                                                  0                     0   \n",
       "1                                                  0                     0   \n",
       "2                                                  0                     0   \n",
       "3                                                  0                     0   \n",
       "4                                                  0                     0   \n",
       "..                                               ...                   ...   \n",
       "68                                                 0                     0   \n",
       "69                                                 0                     0   \n",
       "70                                                 0                     0   \n",
       "71                                                 0                     0   \n",
       "72                                                 0                     0   \n",
       "\n",
       "    Application Name_xRx Application  \n",
       "0                                  0  \n",
       "1                                  0  \n",
       "2                                  0  \n",
       "3                                  0  \n",
       "4                                  0  \n",
       "..                               ...  \n",
       "68                                 0  \n",
       "69                                 0  \n",
       "70                                 0  \n",
       "71                                 0  \n",
       "72                                 0  \n",
       "\n",
       "[66 rows x 28 columns]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dummy other columns in data_copy\n",
    "dummies = pd.get_dummies(data_copy[[\"Tower Name\",\"Application Name\"]],drop_first= True)\n",
    "dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([66, 65, 57, 31, 51, 71, 15, 27, 26, 24, 54, 11, 32, 68, 53, 37, 29,\n",
       "            50, 56,  1, 21,  2, 60, 39, 35, 59, 23, 62, 10, 22, 18, 64, 38, 20,\n",
       "            67,  7, 49, 14, 58],\n",
       "           dtype='int64')"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dummies = dummies.loc[training_index,:]\n",
    "testing_dummies = dummies.loc[testing_index,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.concat([train_data,training_dummies],axis = 1)\n",
    "test_data = pd.concat([test_data,testing_dummies],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=3, max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=2, min_samples_split=3,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=600, n_jobs=None,\n",
       "            oob_score=False, random_state=10, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_model = RandomForestClassifier(max_depth = 3,\n",
    "                                 max_features = None,\n",
    "                                 n_estimators = 600,\n",
    "                                 min_samples_split = 3,\n",
    "                                 min_samples_leaf = 2,\n",
    "                                 random_state = 10)\n",
    "rf_model.fit(train_data,y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------Training Result random forest--------------- \n",
      " \n",
      "\n",
      "[[22  5]\n",
      " [ 0 12]]\n",
      "accuracy --  0.8717948717948718\n",
      "precision_score --  0.7058823529411765\n",
      "recall_score --  1.0\n",
      "f1_score --  0.8275862068965517\n",
      "classification report --- \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.81      0.90        27\n",
      "           1       0.71      1.00      0.83        12\n",
      "\n",
      "   micro avg       0.87      0.87      0.87        39\n",
      "   macro avg       0.85      0.91      0.86        39\n",
      "weighted avg       0.91      0.87      0.88        39\n",
      "\n",
      "---------------Testing Result random forest--------------- \n",
      " \n",
      "\n",
      "[[19  2]\n",
      " [ 1  5]]\n",
      "accuracy --  0.8888888888888888\n",
      "precision_score --  0.7142857142857143\n",
      "recall_score --  0.8333333333333334\n",
      "f1_score --  0.7692307692307692\n",
      "classification report --- \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.90      0.93        21\n",
      "           1       0.71      0.83      0.77         6\n",
      "\n",
      "   micro avg       0.89      0.89      0.89        27\n",
      "   macro avg       0.83      0.87      0.85        27\n",
      "weighted avg       0.90      0.89      0.89        27\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## prediction\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score,confusion_matrix,classification_report\n",
    "\n",
    "prediction_rf_train = rf_model.predict(train_data)\n",
    "\n",
    "print(\"---------------Training Result random forest--------------- \\n \\n\")\n",
    "print(confusion_matrix(y_train1,prediction_rf_train))\n",
    "print(\"accuracy -- \" , accuracy_score(y_train1,prediction_rf_train))\n",
    "print(\"precision_score -- \" , precision_score(y_train1,prediction_rf_train))\n",
    "print(\"recall_score -- \" , recall_score(y_train1,prediction_rf_train))\n",
    "print(\"f1_score -- \" , f1_score(y_train1,prediction_rf_train))\n",
    "print(\"classification report --- \\n\",classification_report(y_train1,prediction_rf_train))\n",
    "\n",
    "prediction_rf_test = rf_model.predict(test_data)\n",
    "\n",
    "print(\"---------------Testing Result random forest--------------- \\n \\n\")\n",
    "print(confusion_matrix(y_test1,prediction_rf_test))\n",
    "print(\"accuracy -- \" , accuracy_score(y_test1,prediction_rf_test))\n",
    "print(\"precision_score -- \" , precision_score(y_test1,prediction_rf_test))\n",
    "print(\"recall_score -- \" , recall_score(y_test1,prediction_rf_test))\n",
    "print(\"f1_score -- \" , f1_score(y_test1,prediction_rf_test))\n",
    "print(\"classification report --- \\n\",classification_report(y_test1,prediction_rf_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here our aim will be any actionable maill shoul not be classified as non actionable.so we have to decrease false positive for non actionable as positive. which means we have to reduce precision for non actionable as positive ((1,2) cell in confusion matrix)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------Training Result SVM--------------- \n",
      " \n",
      "\n",
      "[[22  5]\n",
      " [ 0 12]]\n",
      "accuracy --  0.8717948717948718\n",
      "precision_score --  0.7058823529411765\n",
      "recall_score --  1.0\n",
      "f1_score --  0.8275862068965517\n",
      "classification report --- \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.81      0.90        27\n",
      "           1       0.71      1.00      0.83        12\n",
      "\n",
      "   micro avg       0.87      0.87      0.87        39\n",
      "   macro avg       0.85      0.91      0.86        39\n",
      "weighted avg       0.91      0.87      0.88        39\n",
      "\n",
      "classification report --- \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.90      0.93        21\n",
      "           1       0.71      0.83      0.77         6\n",
      "\n",
      "   micro avg       0.89      0.89      0.89        27\n",
      "   macro avg       0.83      0.87      0.85        27\n",
      "weighted avg       0.90      0.89      0.89        27\n",
      "\n",
      "---------------Testing Result SVM--------------- \n",
      " \n",
      "\n",
      "[[19  2]\n",
      " [ 1  5]]\n",
      "accuracy --  0.8888888888888888\n",
      "precision_score --  0.7142857142857143\n",
      "recall_score --  0.8333333333333334\n",
      "f1_score --  0.7692307692307692\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "from sklearn.svm import LinearSVC\n",
    "svm_clf = LinearSVC(max_iter = 400,\n",
    "                   C = 1,\n",
    "                   class_weight = 'balanced')\n",
    "\n",
    "\n",
    "# params = {'max_iter': (200,400,500,1000),\n",
    "#          \"C\" : (.001,.002,.005,.009,.01,.02,.05,1),\n",
    "#          \"class_weight\" : [None,'balanced']}\n",
    "\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# grid_search = GridSearchCV(svm_clf,param_grid= params, n_jobs=-1, verbose=1)\n",
    "\n",
    "\n",
    "# grid_search.fit(train_data,y_tr)\n",
    "\n",
    "# best_svm_clf = grid_search.best_estimator_\n",
    "# print(\"best svm features -- \\n\",best_svm_clf)\n",
    "# print(\"\\n\")\n",
    "\n",
    "svm_clf.fit(train_data,y_train1)\n",
    "\n",
    "## prediction\n",
    "\n",
    "prediction_best_svm_train = svm_clf.predict(train_data)\n",
    "\n",
    "print(\"---------------Training Result SVM--------------- \\n \\n\")\n",
    "print(confusion_matrix(y_train1,prediction_best_svm_train))\n",
    "print(\"accuracy -- \" , accuracy_score(y_train1,prediction_best_svm_train))\n",
    "print(\"precision_score -- \" , precision_score(y_train1,prediction_best_svm_train))\n",
    "print(\"recall_score -- \" , recall_score(y_train1,prediction_best_svm_train))\n",
    "print(\"f1_score -- \" , f1_score(y_train1,prediction_best_svm_train))\n",
    "print(\"classification report --- \\n\",classification_report(y_train1,prediction_best_svm_train))\n",
    "\n",
    "prediction_best_svm_test = svm_clf.predict(test_data)\n",
    "\n",
    "print(\"classification report --- \\n\",classification_report(y_test1,prediction_best_svm_test))\n",
    "print(\"---------------Testing Result SVM--------------- \\n \\n\")\n",
    "print(confusion_matrix(y_test1,prediction_best_svm_test))\n",
    "print(\"accuracy -- \" , accuracy_score(y_test1,prediction_best_svm_test))\n",
    "print(\"precision_score -- \" , precision_score(y_test1,prediction_best_svm_test))\n",
    "print(\"recall_score -- \" , recall_score(y_test1,prediction_best_svm_test))\n",
    "print(\"f1_score -- \" , f1_score(y_test1,prediction_best_svm_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word2Vec with RF not using pipeline¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_embedding_feature(tokenized_data):\n",
    "    wordvec_arrays = np.zeros((len(tokenized_data), 50)) \n",
    "    \n",
    "    for i in range(len((tokenized_data))):\n",
    "        size = len(tokenized_data[i])\n",
    "        aggregated_wv = np.zeros(50)\n",
    "\n",
    "        for word in tokenized_data[i]:\n",
    "            try:\n",
    "                aggregated_wv += model_w2v[word]\n",
    "            except:\n",
    "                aggregated_wv += np.zeros(50)\n",
    "\n",
    "        aggregated_wv = aggregated_wv / size\n",
    "        wordvec_arrays[i] = aggregated_wv\n",
    "    return pd.DataFrame(wordvec_arrays) \n",
    "\n",
    "\n",
    "def feature_extraction_2(df_train,df_test = None):\n",
    "    train_tokenized_mails = df_train.apply(lambda x : x.split()).reset_index(drop= 'first')\n",
    "    model_w2v = gensim.models.Word2Vec(train_tokenized_mails,\n",
    "                          size = 50,\n",
    "                          window = 3,\n",
    "                          min_count = 1,\n",
    "                          sg = 1,\n",
    "                          negative = 5,\n",
    "                          workers = 4,\n",
    "                          seed = 34)\n",
    "\n",
    "    model_w2v.train(train_tokenized_mails, total_examples= len(df_train), epochs=20)\n",
    "    \n",
    "    print(\"Features -- \\n\", model_w2v.wv.vocab.keys())\n",
    "    train_wordvec_df = word_embedding_feature(train_tokenized_mails)\n",
    "\n",
    "    if df_test != None:\n",
    "        test_tokenized_mails = df_test.apply(lambda x : x.split()).reset_index(drop= 'first')\n",
    "        test_wordvec_df = word_embedding_feature(test_tokenized_mails)\n",
    "    else:\n",
    "        test_wordvec_df = None\n",
    "    return train_wordvec_df,test_wordvec_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from wordcloud import STOPWORDS \n",
    "import spacy\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "\n",
    "def prediction_single_observation(tower_name,application_name,email_subject,email_body):\n",
    "    \n",
    "    # input\n",
    "    tower_nm = str(tower_name)\n",
    "    app_nm = str(application_name)\n",
    "    email_sb = str(email_subject)\n",
    "    email_bdy = \"\"\n",
    "    \n",
    "    #preprocessing\n",
    "    combined = tower_nm + \" \" + app_nm + \" \" + email_sb + \" \" + email_bdy\n",
    "    \n",
    "    combined = re.sub('[^A-Za-z]',\" \",combined)\n",
    "    _RE_COMBINE_WHITESPACE = re.compile(r\"\\s+\")\n",
    "    combined = _RE_COMBINE_WHITESPACE.sub(\" \", combined).strip()\n",
    "    stopwords = set(STOPWORDS) \n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    combined = combined.lower()\n",
    "    combined = \" \".join(word for word in combined.split() if len(word) > 2)\n",
    "    combined = \" \".join([word for word in combined.split() if word not in stopwords])\n",
    "    combined = \" \".join(token.lemma_ for token in nlp(combined))\n",
    "    \n",
    "    # Feature Extraction\n",
    "    # load the feature extarctor\n",
    "    tf_idf = pickle.load(open(\"tfidf.pkl\", 'rb'))\n",
    "    \n",
    "    combined = pd.Series(combined)\n",
    "    test_data = tf_idf.transform(combined)\n",
    "    \n",
    "    # load the model from disk\n",
    "    loaded_model = pickle.load(open(\"random_forest_tfidf.pkl\", 'rb'))\n",
    "    result = loaded_model.predict(test_data)\n",
    "    \n",
    "    if result[0] == 0:\n",
    "        print(\"Actionable\")\n",
    "        \n",
    "    else:\n",
    "        print(\"Non Actionable\")\n",
    "\n",
    "        \n",
    "        \n",
    "    \n",
    "\n",
    "def prediction_data(path):\n",
    "    \n",
    "    # Reading\n",
    "    try:\n",
    "        data = pd.read_excel(path) \n",
    "    except:\n",
    "        data = pd.read_csv(path) \n",
    "    \n",
    "    \n",
    "    #preprocessing\n",
    "    data['combined'] = data.apply(lambda x : f\"{x[0]} {x[1]} {x[2]}\",axis = 1)\n",
    "    data[\"combined\"] = Preprocessing_lemmatization_spacy(data, \"combined\")\n",
    "    \n",
    "    \n",
    "    # Feature Extraction\n",
    "    # load the feature extarctor\n",
    "    tf_idf = pickle.load(open(\"tfidf.pkl\", 'rb'))\n",
    "    test_data = tf_idf.transform(data[\"combined\"])\n",
    "    \n",
    "    # load the model \n",
    "    loaded_model = pickle.load(open(\"random_forest_tfidf.pkl\", 'rb'))\n",
    "    result = loaded_model.predict(test_data)\n",
    "    #print(result)\n",
    "    \n",
    "    #concat prediction\n",
    "    data[\"Flag\"] = result\n",
    "    data[\"Flag\"] = data[\"Flag\"].map({0 : \"Actionable\" , 1 : \"Non Actionable\"})\n",
    "    \n",
    "    data.to_csv(\"result_data.csv\")\n",
    "    print(\"check data in ypur current directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actionable\n"
     ]
    }
   ],
   "source": [
    "prediction_single_observation('Core Pharmacy' ,' PharmRDS-Accredo RealTime Messages','error alert please solve',\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check data in ypur current directory\n"
     ]
    }
   ],
   "source": [
    "prediction_data(\"Book1.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install -c conda-forge pywin32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pywin32 in c:\\users\\chayan\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (228)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 19.2.3, however version 20.2.3 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!py -3.7 -m pip install pywin32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed arguments are: Namespace(destination='C:\\\\Users\\\\Chayan\\\\Anaconda3\\\\Lib\\\\site-packages', install=True, quiet=False, remove=False, silent=False, wait=None)\n",
      "\n",
      "Copied pythoncom37.dll to C:\\Users\\Chayan\\Anaconda3\\pythoncom37.dll\n",
      "\n",
      "Copied pywintypes37.dll to C:\\Users\\Chayan\\Anaconda3\\pywintypes37.dll\n",
      "\n",
      "You do not have the permissions to install COM objects.\n",
      "\n",
      "The sample COM objects were not registered.\n",
      "\n",
      "-> Software\\Python\\PythonCore\\3.7\\Help[None]=None\n",
      "\n",
      "-> Software\\Python\\PythonCore\\3.7\\Help\\Pythonwin Reference[None]='C:\\\\Users\\\\Chayan\\\\Anaconda3\\\\Lib\\\\site-packages\\\\PyWin32.chm'\n",
      "\n",
      "Pythonwin has been registered in context menu\n",
      "\n",
      "Shortcut for Pythonwin created\n",
      "\n",
      "Shortcut to documentation created\n",
      "\n",
      "The pywin32 extensions were successfully installed.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chayan\\Anaconda3\\Scripts\\pywin32_postinstall.py:164: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "\n",
      "  import imp\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python C:\\Users\\Chayan\\Anaconda3\\Scripts\\pywin32_postinstall.py -install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chayan\\Anaconda3\\lib\\site-packages\\pywin32_system32;C:\\Users\\Chayan\\Anaconda3\\lib\\site-packages\\pywin32_system32;C:\\Users\\Chayan\\Anaconda3\\lib\\site-packages\\pywin32_system32;C:\\Users\\Chayan\\Anaconda3;C:\\Users\\Chayan\\Anaconda3\\Library\\mingw-w64\\bin;C:\\Users\\Chayan\\Anaconda3\\Library\\usr\\bin;C:\\Users\\Chayan\\Anaconda3\\Library\\bin;C:\\Users\\Chayan\\Anaconda3\\Scripts;C:\\Users\\Chayan\\Anaconda3\\bin;C:\\Users\\Chayan\\Anaconda3\\condabin;C:\\Users\\Chayan\\Anaconda3\\lib\\site-packages\\pywin32_system32;C:\\Users\\Chayan\\Anaconda3\\condabin\\..;C:\\Users\\Chayan\\Anaconda3\\condabin\\..\\Library\\mingw-w64\\bin;C:\\Users\\Chayan\\Anaconda3\\condabin\\..\\Library\\usr\\bin;C:\\Users\\Chayan\\Anaconda3\\condabin\\..\\Library\\bin;C:\\Users\\Chayan\\Anaconda3\\condabin\\..\\Scripts;C:\\Users\\Chayan\\Anaconda3\\condabin\\..\\bin;C:\\Program Files\\Java\\jdk1.8.0_211\\bin;C:\\Program Files (x86)\\Common Files\\Oracle\\Java\\javapath;C:\\Windows\\system32;C:\\Windows;C:\\Windows\\System32\\Wbem;C:\\Windows\\System32\\WindowsPowerShell\\v1.0\\;C:\\Users\\Chayan\\AppData\\Local\\Programs\\Python\\Python37\\Scripts;C:\\Users\\Chayan\\AppData\\Local\\Programs\\Python\\Python37;C:\\Users\\Chayan;C:\\Program Files\\Git\\cmd;C:\\Users\\Chayan\\AppData\\Local\\Programs\\Python\\Python37\\DLLs;C:/Program Files/Tesseract-OCR/tesseract.exe;C:\\Program Files\\heroku\\bin;C:\\Users\\Chayan\\AppData\\Roaming\\Python\\Python37\\Scripts;C:\\Users\\Chayan\\Anaconda3\\Scripts;C:\\Users\\Chayan\\Anaconda3;C:\\Users\\Chayan\\AppData\\Local\\Programs\\Python\\Python37;C:\\Users\\Chayan\\AppData\\Local\\Programs\\Python\\Python37\\Lib\\site-packages\\pywin32_system32;C:\\Users\\Chayan\\Anaconda3\\Lib\\site-packages\\pywin32_system32;C:\\Users\\Chayan\\AppData\\Local\\Programs\\Python\\Python37\\Lib\\site-packages\\win32\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.environ[\"PATH\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'getwd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-75ffe2fd3048>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgetwd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwin32com\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'getwd' is not defined"
     ]
    }
   ],
   "source": [
    "import win32com.client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlook = win32com.client.Dispatch(\"Outlook.Application\").GetNamespace(\"MAPI\")\n",
    "\n",
    "inbox = outlook.GetDefaultFolder(6) # \"6\" refers to the index of a folder - in this case,\n",
    "                                    # the inbox. You can change that number to reference\n",
    "                                    # any other folder\n",
    "messages = inbox.Items\n",
    "message = messages.GetLast()\n",
    "body_content = message.body\n",
    "print(body_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
