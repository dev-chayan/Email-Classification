{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Chayan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from wordcloud import WordCloud, STOPWORDS \n",
    "import matplotlib.pyplot as plt \n",
    "from nltk import PorterStemmer\n",
    "# nltk.download(\"wordnet\")\n",
    "from nltk import WordNetLemmatizer\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tower Name</th>\n",
       "      <th>Application Name</th>\n",
       "      <th>Email Subject</th>\n",
       "      <th>Flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Core Pharmacy</td>\n",
       "      <td>PharmRDS-Accredo RealTime Messages</td>\n",
       "      <td>Production - Accredo Real Time Order Process S...</td>\n",
       "      <td>Actionable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Core Pharmacy</td>\n",
       "      <td>IVR - Web Service</td>\n",
       "      <td>Splunk Alert: SO IVR - Pharmacy Migration Coor...</td>\n",
       "      <td>Actionable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Core Pharmacy</td>\n",
       "      <td>ISAM- Web Service</td>\n",
       "      <td>Splunk Alert: ISAM - Slowness</td>\n",
       "      <td>Actionable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Core Pharmacy</td>\n",
       "      <td>Migration Co-Ordinaor</td>\n",
       "      <td>Splunk Alert: Migration_Coordinator_500 Clone</td>\n",
       "      <td>Actionable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Core Pharmacy</td>\n",
       "      <td>Claim Realm - Web Service</td>\n",
       "      <td>Splunk Alert: Claim Realm Service - Slowness A...</td>\n",
       "      <td>Actionable</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Tower Name                    Application Name  \\\n",
       "0  Core Pharmacy  PharmRDS-Accredo RealTime Messages   \n",
       "1  Core Pharmacy                   IVR - Web Service   \n",
       "2  Core Pharmacy                   ISAM- Web Service   \n",
       "3  Core Pharmacy               Migration Co-Ordinaor   \n",
       "4  Core Pharmacy           Claim Realm - Web Service   \n",
       "\n",
       "                                       Email Subject        Flag  \n",
       "0  Production - Accredo Real Time Order Process S...  Actionable  \n",
       "1  Splunk Alert: SO IVR - Pharmacy Migration Coor...  Actionable  \n",
       "2                      Splunk Alert: ISAM - Slowness  Actionable  \n",
       "3      Splunk Alert: Migration_Coordinator_500 Clone  Actionable  \n",
       "4  Splunk Alert: Claim Realm Service - Slowness A...  Actionable  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel(\"Email_Classificaion.xlsx\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73, 4)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Actionable        48\n",
       "Non Actionable    18\n",
       "Name: Flag, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Flag'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tower Name          0\n",
       "Application Name    0\n",
       "Email Subject       0\n",
       "Flag                7\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tower Name</th>\n",
       "      <th>Application Name</th>\n",
       "      <th>Email Subject</th>\n",
       "      <th>Flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Core Pharmacy</td>\n",
       "      <td>PharmRDS-Accredo RealTime Messages</td>\n",
       "      <td>Production - Accredo Real Time Order Process S...</td>\n",
       "      <td>Actionable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Core Pharmacy</td>\n",
       "      <td>IVR - Web Service</td>\n",
       "      <td>Splunk Alert: SO IVR - Pharmacy Migration Coor...</td>\n",
       "      <td>Actionable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Core Pharmacy</td>\n",
       "      <td>ISAM- Web Service</td>\n",
       "      <td>Splunk Alert: ISAM - Slowness</td>\n",
       "      <td>Actionable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Core Pharmacy</td>\n",
       "      <td>Migration Co-Ordinaor</td>\n",
       "      <td>Splunk Alert: Migration_Coordinator_500 Clone</td>\n",
       "      <td>Actionable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Core Pharmacy</td>\n",
       "      <td>Claim Realm - Web Service</td>\n",
       "      <td>Splunk Alert: Claim Realm Service - Slowness A...</td>\n",
       "      <td>Actionable</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Tower Name                    Application Name  \\\n",
       "0  Core Pharmacy  PharmRDS-Accredo RealTime Messages   \n",
       "1  Core Pharmacy                   IVR - Web Service   \n",
       "2  Core Pharmacy                   ISAM- Web Service   \n",
       "3  Core Pharmacy               Migration Co-Ordinaor   \n",
       "4  Core Pharmacy           Claim Realm - Web Service   \n",
       "\n",
       "                                       Email Subject        Flag  \n",
       "0  Production - Accredo Real Time Order Process S...  Actionable  \n",
       "1  Splunk Alert: SO IVR - Pharmacy Migration Coor...  Actionable  \n",
       "2                      Splunk Alert: ISAM - Slowness  Actionable  \n",
       "3      Splunk Alert: Migration_Coordinator_500 Clone  Actionable  \n",
       "4  Splunk Alert: Claim Realm Service - Slowness A...  Actionable  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ger rid of na values in Flag\n",
    "data = data[~data['Flag'].isna()]\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Actionable        48\n",
       "Non Actionable    18\n",
       "Name: Flag, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Flag'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy['combined'] = data_copy.apply(lambda x : f\"{x[0]} {x[1]} {x[2]}\",axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tower Name</th>\n",
       "      <th>Application Name</th>\n",
       "      <th>Email Subject</th>\n",
       "      <th>Flag</th>\n",
       "      <th>combined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Core Pharmacy</td>\n",
       "      <td>PharmRDS-Accredo RealTime Messages</td>\n",
       "      <td>Production - Accredo Real Time Order Process S...</td>\n",
       "      <td>Actionable</td>\n",
       "      <td>Core Pharmacy PharmRDS-Accredo RealTime Messag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Core Pharmacy</td>\n",
       "      <td>IVR - Web Service</td>\n",
       "      <td>Splunk Alert: SO IVR - Pharmacy Migration Coor...</td>\n",
       "      <td>Actionable</td>\n",
       "      <td>Core Pharmacy IVR - Web Service Splunk Alert: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Core Pharmacy</td>\n",
       "      <td>ISAM- Web Service</td>\n",
       "      <td>Splunk Alert: ISAM - Slowness</td>\n",
       "      <td>Actionable</td>\n",
       "      <td>Core Pharmacy ISAM- Web Service Splunk Alert: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Core Pharmacy</td>\n",
       "      <td>Migration Co-Ordinaor</td>\n",
       "      <td>Splunk Alert: Migration_Coordinator_500 Clone</td>\n",
       "      <td>Actionable</td>\n",
       "      <td>Core Pharmacy Migration Co-Ordinaor Splunk Ale...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Core Pharmacy</td>\n",
       "      <td>Claim Realm - Web Service</td>\n",
       "      <td>Splunk Alert: Claim Realm Service - Slowness A...</td>\n",
       "      <td>Actionable</td>\n",
       "      <td>Core Pharmacy Claim Realm - Web Service Splunk...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Tower Name                    Application Name  \\\n",
       "0  Core Pharmacy  PharmRDS-Accredo RealTime Messages   \n",
       "1  Core Pharmacy                   IVR - Web Service   \n",
       "2  Core Pharmacy                   ISAM- Web Service   \n",
       "3  Core Pharmacy               Migration Co-Ordinaor   \n",
       "4  Core Pharmacy           Claim Realm - Web Service   \n",
       "\n",
       "                                       Email Subject        Flag  \\\n",
       "0  Production - Accredo Real Time Order Process S...  Actionable   \n",
       "1  Splunk Alert: SO IVR - Pharmacy Migration Coor...  Actionable   \n",
       "2                      Splunk Alert: ISAM - Slowness  Actionable   \n",
       "3      Splunk Alert: Migration_Coordinator_500 Clone  Actionable   \n",
       "4  Splunk Alert: Claim Realm Service - Slowness A...  Actionable   \n",
       "\n",
       "                                            combined  \n",
       "0  Core Pharmacy PharmRDS-Accredo RealTime Messag...  \n",
       "1  Core Pharmacy IVR - Web Service Splunk Alert: ...  \n",
       "2  Core Pharmacy ISAM- Web Service Splunk Alert: ...  \n",
       "3  Core Pharmacy Migration Co-Ordinaor Splunk Ale...  \n",
       "4  Core Pharmacy Claim Realm - Web Service Splunk...  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_copy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Preprocessing_stemming(df,column_name):\n",
    "    # Email Subject column\n",
    "    df[column_name] = df[column_name].apply(lambda x: re.sub('[^A-Za-z]',\" \",x))\n",
    "    df[column_name] = df[column_name].replace([\" \",\"  \",\"   \"],\" \",regex = True)\n",
    "    stopwords = set(STOPWORDS) \n",
    "    stemmer = PorterStemmer()\n",
    "    df[column_name] = df[column_name].apply(lambda x : x.lower())\n",
    "    df[column_name] = df[column_name].apply(lambda x : \" \".join(word for word in x if len(word) > 2))\n",
    "    df[column_name] = df[column_name].apply(lambda x : \" \".join([word for word in x.split() if word not in stopwords]))\n",
    "    df[column_name] = df[column_name].apply(lambda x : stemmer.stem(x)) \n",
    "    return df[column_name]\n",
    "\n",
    "\n",
    "def Preprocessing_lemmatization(df,column_name):\n",
    "    # Email Subject column\n",
    "    df[column_name] = df[column_name].apply(lambda x: re.sub('[^A-Za-z]',\" \",x))\n",
    "    df[column_name] = df[column_name].replace([\" \",\"  \",\"   \"],\" \",regex = True)\n",
    "    stopwords = set(STOPWORDS) \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    df[column_name] = df[column_name].apply(lambda x : x.lower())\n",
    "    df[column_name] = df[column_name].apply(lambda x : \" \".join(word for word in x if len(word) > 2))\n",
    "    df[column_name] = df[column_name].apply(lambda x : \" \".join([word for word in x.split() if word not in stopwords]))\n",
    "    df[column_name] = df[column_name].apply(lambda x : lemmatizer.lemmatize(x)) \n",
    "    return df[column_name]\n",
    "\n",
    "\n",
    "def Preprocessing_lemmatization_spacy(df,column_name):\n",
    "    # Email Subject column\n",
    "    df[column_name] = df[column_name].apply(lambda x: re.sub('[^A-Za-z]',\" \",x))\n",
    "    df[column_name] = df[column_name].replace([\" \",\"  \",\"   \"],\" \",regex = True)\n",
    "    stopwords = set(STOPWORDS) \n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    df[column_name] = df[column_name].apply(lambda x : x.lower())\n",
    "    df[column_name] = df[column_name].apply(lambda x : \" \".join(word for word in x.split() if len(word) > 2))\n",
    "    df[column_name] = df[column_name].apply(lambda x : \" \".join([word for word in x.split() if word not in stopwords]))\n",
    "    df[column_name] = df[column_name].apply(lambda x : \" \".join(token.lemma_ for token in nlp(x))) \n",
    "    return df[column_name]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "import gensim\n",
    "\n",
    "def feature_extraction_1(df_train,df_test = None):\n",
    "    vectorizer = TfidfVectorizer(use_idf = True, ngram_range = (1,2),max_df = 5,min_df = 3,max_features = 100)\n",
    "    train_data = vectorizer.fit_transform(df_train)\n",
    "    if df_test != None:\n",
    "        test_data = vectorizer.transform(df_test)\n",
    "    else:\n",
    "        test_data = None\n",
    "        \n",
    "    print(\"Features : \\n\", vectorizer.vocabulary_)\n",
    "    return train_data,test_data\n",
    "\n",
    "\n",
    "\n",
    "def word_embedding_feature(tokenized_data):\n",
    "    wordvec_arrays = np.zeros((len(tokenized_data), 50)) \n",
    "    \n",
    "    for i in range(len((tokenized_data))):\n",
    "        size = len(tokenized_data[i])\n",
    "        aggregated_wv = np.zeros(50)\n",
    "\n",
    "        for word in tokenized_data[i]:\n",
    "            try:\n",
    "                aggregated_wv += model_w2v[word]\n",
    "            except:\n",
    "                aggregated_wv += np.zeros(50)\n",
    "\n",
    "        aggregated_wv = aggregated_wv / size\n",
    "        wordvec_arrays[i] = aggregated_wv\n",
    "    return pd.DataFrame(wordvec_arrays) \n",
    "\n",
    "\n",
    "def feature_extraction_2(df_train,df_test = None):\n",
    "    train_tokenized_mails = df_train.apply(lambda x : x.split()).reset_index(drop= 'first')\n",
    "    model_w2v = gensim.models.Word2Vec(train_tokenized_mails,\n",
    "                          size = 50,\n",
    "                          window = 3,\n",
    "                          min_count = 1,\n",
    "                          sg = 1,\n",
    "                          negative = 5,\n",
    "                          workers = 4,\n",
    "                          seed = 34)\n",
    "\n",
    "    model_w2v.train(train_tokenized_mails, total_examples= len(df_train), epochs=20)\n",
    "    \n",
    "    print(\"Features -- \\n\", model_w2v.wv.vocab.keys())\n",
    "    train_wordvec_df = word_embedding_feature(train_tokenized_mails)\n",
    "\n",
    "    if df_test != None:\n",
    "        test_tokenized_mails = df_test.apply(lambda x : x.split()).reset_index(drop= 'first')\n",
    "        test_wordvec_df = word_embedding_feature(test_tokenized_mails)\n",
    "    else:\n",
    "        test_wordvec_df = None\n",
    "    return train_wordvec_df,test_wordvec_df\n",
    "\n",
    "\n",
    "\n",
    "def new_word_embedding_feature_with_tfidf(tokenized_data,tfidf_data):\n",
    "    wordvec_arrays = np.zeros((len(tokenized_data), 50)) \n",
    "    \n",
    "    for i in range(len((tokenized_data))):\n",
    "        \n",
    "        size = len(tfidf_data.loc[i,tfidf_data.iloc[i,:] != 0])\n",
    "        if size == 0:\n",
    "            size = 1\n",
    "            \n",
    "        aggregated_wv = np.zeros(50)\n",
    "\n",
    "        for word in tokenized_data[i]:\n",
    "            try:\n",
    "                aggregated_wv += model_w2v[word] * tfidf_data[word][i]\n",
    "            except:\n",
    "                aggregated_wv += np.zeros(50)\n",
    "\n",
    "        aggregated_wv = aggregated_wv / size\n",
    "        wordvec_arrays[i] = aggregated_wv\n",
    "    return pd.DataFrame(wordvec_arrays) \n",
    "\n",
    "def is_phrase_in(phrase, text):\n",
    "        return re.search(r\"\\b{}\\b\".format(phrase), text, re.IGNORECASE) is not None\n",
    "\n",
    "\n",
    "def replace_bigram(sentence,dict_):\n",
    "    for bigram in dict_.keys():\n",
    "        if is_phrase_in(bigram,sentence):\n",
    "            sentence = sentence.replace(bigram,dict_[bigram])\n",
    "    return sentence\n",
    "\n",
    "\n",
    "\n",
    "def feature_extraction_3(df_train,df_test = None):\n",
    "    doc = \" \".join(sent for sent in df_train)\n",
    "    wordcloud = WordCloud(width = 800, height = 800, \n",
    "                background_color ='white', \n",
    "                stopwords = stopwords, \n",
    "                min_font_size = 20,\n",
    "                collocation_threshold = 20).generate(doc) \n",
    "    top_50_words = list(wordcloud.words_.keys())[:50]\n",
    "    # changing bigrams to unigrams in X_train for word_embedding\n",
    "    \n",
    "    change_dict = {}\n",
    "    for word in top_50_words:\n",
    "        if len(word.split()) > 1:\n",
    "            change_dict[word] = word.replace(\" \",\"_\")\n",
    "\n",
    "    top_50_words_changed = [change_dict[word] if word in list(change_dict.keys()) else word for word in top_50_words] \n",
    "    \n",
    "\n",
    "    X_train_copy = df_train.copy()\n",
    "    X_train_copy = X_train_copy.apply(lambda x: replace_bigram(x,change_dict))\n",
    "    \n",
    "    # create tfidf based on these top_50_words\n",
    "    tfidf_1 = TfidfVectorizer(vocabulary = top_50_words_changed)\n",
    "    new_train_data = tfidf_1.fit_transform(X_train_copy)\n",
    "    new_train_data = pd.DataFrame( new_train_data.toarray() , columns = top_50_words_changed)\n",
    "    \n",
    "    # create word_embedding \n",
    "    train_tokenized_mails = X_train_copy.apply(lambda x : x.split()).reset_index(drop= 'first')\n",
    "    model_w2v = gensim.models.Word2Vec(train_tokenized_mails,\n",
    "                          size = 50,\n",
    "                          window = 3,\n",
    "                          min_count = 1,\n",
    "                          sg = 1,\n",
    "                          negative = 5,\n",
    "                          workers = 4,\n",
    "                          seed = 34)\n",
    "    model_w2v.train(train_tokenized_mails, total_examples= len(X_train_copy), epochs=20)\n",
    "    print(\"Features -- \\n\", model_w2v.wv.vocab.keys())\n",
    "    train_wordvec_df = new_word_embedding_feature_with_tfidf(train_tokenized_mails,new_train_data)\n",
    "    \n",
    "    \n",
    "    if df_test!= None:\n",
    "        X_test_copy = df_test.copy()\n",
    "        X_test_copy = X_test_copy.apply(lambda x: replace_bigram(x,change_dict))\n",
    "        new_test_data = tfidf_1.transform(X_test_copy)\n",
    "        new_test_data = pd.DataFrame(new_test_data.toarray() , columns = top_50_words_changed)        \n",
    "        test_tokenized_mails = X_test_copy.apply(lambda x : x.split()).reset_index(drop= 'first')\n",
    "        test_wordvec_df = new_word_embedding_feature_with_tfidf(test_tokenized_mails,new_test_data)  \n",
    "        \n",
    "    else:\n",
    "        test_wordvec_df = None\n",
    "        \n",
    "    return train_wordvec_df, test_wordvec_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL TRAINING FUNCTION\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score,confusion_matrix,classification_report\n",
    "def train(X_tr,X_te,y_tr,y_te):\n",
    "    \n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.svm import LinearSVC\n",
    "    from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score,confusion_matrix\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    ##### random forest classifier\n",
    "    \n",
    "   \n",
    "    rf_clf = RandomForestClassifier()\n",
    "\n",
    "\n",
    "    params = {\"n_estimators\" : [100,200,400],\n",
    "             \"max_depth\": [2,3,4],\n",
    "             \"min_samples_split\" : [2,3,4,5],\n",
    "             \"class_weight\" : [\"balanced\", \"balanced_subsample\", None]}\n",
    "\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    grid_search = GridSearchCV(rf_clf,param_grid= params, n_jobs=-1, verbose=1)\n",
    "\n",
    "    grid_search.fit(X_tr,y_tr)\n",
    "    \n",
    "    best_rf_clf = grid_search.best_estimator_\n",
    "    print(\"best rf features -- \\n\",best_rf_clf)\n",
    "    print(\"\\n\")\n",
    "    best_rf_clf.fit(X_tr,y_tr)\n",
    "\n",
    "    ## prediction\n",
    "    prediction_best_rf_train = best_rf_clf.predict(X_tr)\n",
    "\n",
    "    print(\"---------------Training Result Random Forest--------------- \\n \\n\")\n",
    "    print(confusion_matrix(y_tr,prediction_best_rf_train))\n",
    "    print(\"accuracy -- \" , accuracy_score(y_tr,prediction_best_rf_train))\n",
    "    print(\"precision_score -- \" , precision_score(y_tr,prediction_best_rf_train))\n",
    "    print(\"recall_score -- \" , recall_score(y_tr,prediction_best_rf_train))\n",
    "    print(\"f1_score -- \" , f1_score(y_tr,prediction_best_rf_train))\n",
    "    print(\"classification report --- \\n\",classification_report(y_tr,prediction_best_rf_train))\n",
    "    \n",
    "    prediction_best_rf_test = best_rf_clf.predict(X_te)\n",
    "\n",
    "    print(\"---------------Testing Result Random Forest--------------- \\n \\n\")\n",
    "    print(confusion_matrix(y_te,prediction_best_rf_test))\n",
    "    print(\"accuracy -- \" , accuracy_score(y_te,prediction_best_rf_test))\n",
    "    print(\"precision_score -- \" , precision_score(y_te,prediction_best_rf_test))\n",
    "    print(\"recall_score -- \" , recall_score(y_te,prediction_best_rf_test))\n",
    "    print(\"f1_score -- \" , f1_score(y_te,prediction_best_rf_test))\n",
    "    print(\"classification report --- \\n\",classification_report(y_te,prediction_best_rf_test))\n",
    "\n",
    "    print(\"\\n\\n\")\n",
    "    ####### SVM classification\n",
    "\n",
    "    svm_clf = LinearSVC()\n",
    "\n",
    "\n",
    "    params = {'max_iter': (200,400,500,1000),\n",
    "             \"C\" : (.001,.002,.005,.009,.01,.02,.05,1),\n",
    "             \"class_weight\" : [None,'balanced']}\n",
    "\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    grid_search = GridSearchCV(svm_clf,param_grid= params, n_jobs=-1, verbose=1)\n",
    "\n",
    "   \n",
    "    grid_search.fit(X_tr,y_tr)\n",
    "\n",
    "    best_svm_clf = grid_search.best_estimator_\n",
    "    print(\"best svm features -- \\n\",best_svm_clf)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    best_svm_clf.fit(X_tr,y_tr)\n",
    "\n",
    "    ## prediction\n",
    "\n",
    "    prediction_best_svm_train = best_svm_clf.predict(X_tr)\n",
    "\n",
    "    print(\"---------------Training Result SVM--------------- \\n \\n\")\n",
    "    print(confusion_matrix(y_tr,prediction_best_svm_train))\n",
    "    print(\"accuracy -- \" , accuracy_score(y_tr,prediction_best_svm_train))\n",
    "    print(\"precision_score -- \" , precision_score(y_tr,prediction_best_svm_train))\n",
    "    print(\"recall_score -- \" , recall_score(y_tr,prediction_best_svm_train))\n",
    "    print(\"f1_score -- \" , f1_score(y_tr,prediction_best_svm_train))\n",
    "    print(\"classification report --- \\n\",classification_report(y_tr,prediction_best_svm_train))\n",
    "\n",
    "    prediction_best_svm_test = best_svm_clf.predict(X_te)\n",
    "    \n",
    "    print(\"classification report --- \\n\",classification_report(y_te,prediction_best_rf_test))\n",
    "    print(\"---------------Testing Result SVM--------------- \\n \\n\")\n",
    "    print(confusion_matrix(y_te,prediction_best_svm_test))\n",
    "    print(\"accuracy -- \" , accuracy_score(y_te,prediction_best_svm_test))\n",
    "    print(\"precision_score -- \" , precision_score(y_te,prediction_best_svm_test))\n",
    "    print(\"recall_score -- \" , recall_score(y_te,prediction_best_svm_test))\n",
    "    print(\"f1_score -- \" , f1_score(y_te,prediction_best_svm_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction after split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work Done -- 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy[\"combined\"] = Preprocessing_lemmatization(data_copy, \"combined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = data_copy[\"combined\"]\n",
    "y = data_copy[\"Flag\"].map({\"Actionable\" : 0, \"Non Actionable\" : 1})\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.40, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, test_features = feature_extraction_2(X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chayan\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   21.2s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 324 out of 324 | elapsed:  1.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best rf features -- \n",
      " RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='gini', max_depth=2, max_features='auto',\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=200, n_jobs=None, oob_score=False,\n",
      "            random_state=None, verbose=0, warm_start=False)\n",
      "\n",
      "\n",
      "---------------Training Result Random Forest--------------- \n",
      " \n",
      "\n",
      "[[27  0]\n",
      " [12  0]]\n",
      "accuracy --  0.6923076923076923\n",
      "precision_score --  0.0\n",
      "recall_score --  0.0\n",
      "f1_score --  0.0\n",
      "classification report --- \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      1.00      0.82        27\n",
      "           1       0.00      0.00      0.00        12\n",
      "\n",
      "   micro avg       0.69      0.69      0.69        39\n",
      "   macro avg       0.35      0.50      0.41        39\n",
      "weighted avg       0.48      0.69      0.57        39\n",
      "\n",
      "---------------Testing Result Random Forest--------------- \n",
      " \n",
      "\n",
      "[[21  0]\n",
      " [ 6  0]]\n",
      "accuracy --  0.7777777777777778\n",
      "precision_score --  0.0\n",
      "recall_score --  0.0\n",
      "f1_score --  0.0\n",
      "classification report --- \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.88        21\n",
      "           1       0.00      0.00      0.00         6\n",
      "\n",
      "   micro avg       0.78      0.78      0.78        27\n",
      "   macro avg       0.39      0.50      0.44        27\n",
      "weighted avg       0.60      0.78      0.68        27\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Fitting 3 folds for each of 64 candidates, totalling 192 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chayan\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Chayan\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Chayan\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Chayan\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Chayan\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Chayan\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Chayan\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best svm features -- \n",
      " LinearSVC(C=0.001, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=200,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n",
      "\n",
      "\n",
      "---------------Training Result SVM--------------- \n",
      " \n",
      "\n",
      "[[27  0]\n",
      " [12  0]]\n",
      "accuracy --  0.6923076923076923\n",
      "precision_score --  0.0\n",
      "recall_score --  0.0\n",
      "f1_score --  0.0\n",
      "classification report --- \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      1.00      0.82        27\n",
      "           1       0.00      0.00      0.00        12\n",
      "\n",
      "   micro avg       0.69      0.69      0.69        39\n",
      "   macro avg       0.35      0.50      0.41        39\n",
      "weighted avg       0.48      0.69      0.57        39\n",
      "\n",
      "classification report --- \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.88        21\n",
      "           1       0.00      0.00      0.00         6\n",
      "\n",
      "   micro avg       0.78      0.78      0.78        27\n",
      "   macro avg       0.39      0.50      0.44        27\n",
      "weighted avg       0.60      0.78      0.68        27\n",
      "\n",
      "---------------Testing Result SVM--------------- \n",
      " \n",
      "\n",
      "[[21  0]\n",
      " [ 6  0]]\n",
      "accuracy --  0.7777777777777778\n",
      "precision_score --  0.0\n",
      "recall_score --  0.0\n",
      "f1_score --  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 192 out of 192 | elapsed:    1.2s finished\n",
      "C:\\Users\\Chayan\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Chayan\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Chayan\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Chayan\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Chayan\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Chayan\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "train(train_features, test_features,  y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work Done -- 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, test_features = feature_extraction_3(X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chayan\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    9.1s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   29.6s\n",
      "[Parallel(n_jobs=-1)]: Done 324 out of 324 | elapsed:   47.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best rf features -- \n",
      " RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='gini', max_depth=2, max_features='auto',\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=100, n_jobs=None, oob_score=False,\n",
      "            random_state=None, verbose=0, warm_start=False)\n",
      "\n",
      "\n",
      "---------------Training Result Random Forest--------------- \n",
      " \n",
      "\n",
      "[[27  0]\n",
      " [12  0]]\n",
      "accuracy --  0.6923076923076923\n",
      "precision_score --  0.0\n",
      "recall_score --  0.0\n",
      "f1_score --  0.0\n",
      "---------------Testing Result Random Forest--------------- \n",
      " \n",
      "\n",
      "[[21  0]\n",
      " [ 6  0]]\n",
      "accuracy --  0.7777777777777778\n",
      "precision_score --  0.0\n",
      "recall_score --  0.0\n",
      "f1_score --  0.0\n",
      "\n",
      "\n",
      "\n",
      "Fitting 3 folds for each of 64 candidates, totalling 192 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chayan\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Chayan\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Chayan\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Chayan\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Chayan\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best svm features -- \n",
      " LinearSVC(C=0.001, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=200,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n",
      "\n",
      "\n",
      "---------------Training Result SVM--------------- \n",
      " \n",
      "\n",
      "[[27  0]\n",
      " [12  0]]\n",
      "accuracy --  0.6923076923076923\n",
      "precision_score --  0.0\n",
      "recall_score --  0.0\n",
      "f1_score --  0.0\n",
      "---------------Testing Result SVM--------------- \n",
      " \n",
      "\n",
      "[[21  0]\n",
      " [ 6  0]]\n",
      "accuracy --  0.7777777777777778\n",
      "precision_score --  0.0\n",
      "recall_score --  0.0\n",
      "f1_score --  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 192 out of 192 | elapsed:    0.5s finished\n",
      "C:\\Users\\Chayan\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Chayan\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Chayan\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Chayan\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "train(train_features, test_features,  y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work Done -- 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, test_features = feature_extraction_1(X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chayan\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   18.1s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 324 out of 324 | elapsed:  1.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best rf features -- \n",
      " RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "\n",
      "\n",
      "---------------Training Result Random Forest--------------- \n",
      " \n",
      "\n",
      "[[27  0]\n",
      " [ 9  3]]\n",
      "accuracy --  0.7692307692307693\n",
      "precision_score --  1.0\n",
      "recall_score --  0.25\n",
      "f1_score --  0.4\n",
      "classification report --- \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      1.00      0.86        27\n",
      "           1       1.00      0.25      0.40        12\n",
      "\n",
      "   micro avg       0.77      0.77      0.77        39\n",
      "   macro avg       0.88      0.62      0.63        39\n",
      "weighted avg       0.83      0.77      0.72        39\n",
      "\n",
      "---------------Testing Result Random Forest--------------- \n",
      " \n",
      "\n",
      "[[19  2]\n",
      " [ 6  0]]\n",
      "accuracy --  0.7037037037037037\n",
      "precision_score --  0.0\n",
      "recall_score --  0.0\n",
      "f1_score --  0.0\n",
      "classification report --- \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.90      0.83        21\n",
      "           1       0.00      0.00      0.00         6\n",
      "\n",
      "   micro avg       0.70      0.70      0.70        27\n",
      "   macro avg       0.38      0.45      0.41        27\n",
      "weighted avg       0.59      0.70      0.64        27\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Fitting 3 folds for each of 64 candidates, totalling 192 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chayan\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best svm features -- \n",
      " LinearSVC(C=1, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=200,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n",
      "\n",
      "\n",
      "---------------Training Result SVM--------------- \n",
      " \n",
      "\n",
      "[[27  0]\n",
      " [ 6  6]]\n",
      "accuracy --  0.8461538461538461\n",
      "precision_score --  1.0\n",
      "recall_score --  0.5\n",
      "f1_score --  0.6666666666666666\n",
      "classification report --- \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      1.00      0.90        27\n",
      "           1       1.00      0.50      0.67        12\n",
      "\n",
      "   micro avg       0.85      0.85      0.85        39\n",
      "   macro avg       0.91      0.75      0.78        39\n",
      "weighted avg       0.87      0.85      0.83        39\n",
      "\n",
      "classification report --- \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.90      0.83        21\n",
      "           1       0.00      0.00      0.00         6\n",
      "\n",
      "   micro avg       0.70      0.70      0.70        27\n",
      "   macro avg       0.38      0.45      0.41        27\n",
      "weighted avg       0.59      0.70      0.64        27\n",
      "\n",
      "---------------Testing Result SVM--------------- \n",
      " \n",
      "\n",
      "[[18  3]\n",
      " [ 6  0]]\n",
      "accuracy --  0.6666666666666666\n",
      "precision_score --  0.0\n",
      "recall_score --  0.0\n",
      "f1_score --  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 192 out of 192 | elapsed:    0.8s finished\n"
     ]
    }
   ],
   "source": [
    "train(train_features, test_features,  y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chayan\\Anaconda3\\lib\\site-packages\\dask\\config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  data = yaml.load(f.read()) or {}\n",
      "C:\\Users\\Chayan\\Anaconda3\\lib\\site-packages\\dask\\dataframe\\utils.py:13: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n",
      "C:\\Users\\Chayan\\Anaconda3\\lib\\site-packages\\distributed\\config.py:20: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  defaults = yaml.load(f)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "       importance_type='gain', interaction_constraints='',\n",
       "       learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "       min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "       n_estimators=100, n_jobs=0, num_parallel_tree=1,\n",
       "       objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method='exact',\n",
       "       validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "xg_clf = XGBClassifier()\n",
    "xg_clf.fit(train_features,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------Training Result Xgboost--------------- \n",
      " \n",
      "\n",
      "[[27  0]\n",
      " [12  0]]\n",
      "accuracy --  0.6923076923076923\n",
      "precision_score --  0.0\n",
      "recall_score --  0.0\n",
      "f1_score --  0.0\n",
      "classification report --- \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      1.00      0.82        27\n",
      "           1       0.00      0.00      0.00        12\n",
      "\n",
      "   micro avg       0.69      0.69      0.69        39\n",
      "   macro avg       0.35      0.50      0.41        39\n",
      "weighted avg       0.48      0.69      0.57        39\n",
      "\n",
      "---------------Testing Result Xgboost--------------- \n",
      " \n",
      "\n",
      "[[21  0]\n",
      " [ 6  0]]\n",
      "accuracy --  0.7777777777777778\n",
      "precision_score --  0.0\n",
      "recall_score --  0.0\n",
      "f1_score --  0.0\n",
      "classification report --- \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.88        21\n",
      "           1       0.00      0.00      0.00         6\n",
      "\n",
      "   micro avg       0.78      0.78      0.78        27\n",
      "   macro avg       0.39      0.50      0.44        27\n",
      "weighted avg       0.60      0.78      0.68        27\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## prediction\n",
    "\n",
    "prediction_xg_train = xg_clf.predict(train_features)\n",
    "\n",
    "print(\"---------------Training Result Xgboost--------------- \\n \\n\")\n",
    "print(confusion_matrix(y_train,prediction_xg_train))\n",
    "print(\"accuracy -- \" , accuracy_score(y_train,prediction_xg_train))\n",
    "print(\"precision_score -- \" , precision_score(y_train,prediction_xg_train))\n",
    "print(\"recall_score -- \" , recall_score(y_train,prediction_xg_train))\n",
    "print(\"f1_score -- \" , f1_score(y_train,prediction_xg_train))\n",
    "print(\"classification report --- \\n\",classification_report(y_train,prediction_xg_train))\n",
    "\n",
    "prediction_xg_test = xg_clf.predict(test_features)\n",
    "\n",
    "print(\"---------------Testing Result Xgboost--------------- \\n \\n\")\n",
    "print(confusion_matrix(y_test,prediction_xg_test))\n",
    "print(\"accuracy -- \" , accuracy_score(y_test,prediction_xg_test))\n",
    "print(\"precision_score -- \" , precision_score(y_test,prediction_xg_test))\n",
    "print(\"recall_score -- \" , recall_score(y_test,prediction_xg_test))\n",
    "print(\"f1_score -- \" , f1_score(y_test,prediction_xg_test))\n",
    "print(\"classification report --- \\n\",classification_report(y_test,prediction_xg_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work Done -- 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy[\"combined\"] = Preprocessing_lemmatization_spacy(data_copy, \"combined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tower Name</th>\n",
       "      <th>Application Name</th>\n",
       "      <th>Email Subject</th>\n",
       "      <th>Flag</th>\n",
       "      <th>combined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Core Pharmacy</td>\n",
       "      <td>PharmRDS-Accredo RealTime Messages</td>\n",
       "      <td>Production - Accredo Real Time Order Process S...</td>\n",
       "      <td>Actionable</td>\n",
       "      <td>core pharmacy pharmrd accredo realtime message...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Core Pharmacy</td>\n",
       "      <td>IVR - Web Service</td>\n",
       "      <td>Splunk Alert: SO IVR - Pharmacy Migration Coor...</td>\n",
       "      <td>Actionable</td>\n",
       "      <td>core pharmacy ivr web service splunk alert ivr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Core Pharmacy</td>\n",
       "      <td>ISAM- Web Service</td>\n",
       "      <td>Splunk Alert: ISAM - Slowness</td>\n",
       "      <td>Actionable</td>\n",
       "      <td>core pharmacy isam web service splunk alert is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Core Pharmacy</td>\n",
       "      <td>Migration Co-Ordinaor</td>\n",
       "      <td>Splunk Alert: Migration_Coordinator_500 Clone</td>\n",
       "      <td>Actionable</td>\n",
       "      <td>core pharmacy migration ordinaor splunk alert ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Core Pharmacy</td>\n",
       "      <td>Claim Realm - Web Service</td>\n",
       "      <td>Splunk Alert: Claim Realm Service - Slowness A...</td>\n",
       "      <td>Actionable</td>\n",
       "      <td>core pharmacy claim realm web service splunk a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Tower Name                    Application Name  \\\n",
       "0  Core Pharmacy  PharmRDS-Accredo RealTime Messages   \n",
       "1  Core Pharmacy                   IVR - Web Service   \n",
       "2  Core Pharmacy                   ISAM- Web Service   \n",
       "3  Core Pharmacy               Migration Co-Ordinaor   \n",
       "4  Core Pharmacy           Claim Realm - Web Service   \n",
       "\n",
       "                                       Email Subject        Flag  \\\n",
       "0  Production - Accredo Real Time Order Process S...  Actionable   \n",
       "1  Splunk Alert: SO IVR - Pharmacy Migration Coor...  Actionable   \n",
       "2                      Splunk Alert: ISAM - Slowness  Actionable   \n",
       "3      Splunk Alert: Migration_Coordinator_500 Clone  Actionable   \n",
       "4  Splunk Alert: Claim Realm Service - Slowness A...  Actionable   \n",
       "\n",
       "                                            combined  \n",
       "0  core pharmacy pharmrd accredo realtime message...  \n",
       "1  core pharmacy ivr web service splunk alert ivr...  \n",
       "2  core pharmacy isam web service splunk alert is...  \n",
       "3  core pharmacy migration ordinaor splunk alert ...  \n",
       "4  core pharmacy claim realm web service splunk a...  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_copy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = data_copy[\"combined\"]\n",
    "y = data_copy[\"Flag\"].map({\"Actionable\" : 0, \"Non Actionable\" : 1})\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.40, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, test_features = feature_extraction_1(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "columns not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-91-e17719e1d9ff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_features\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    685\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetnnz\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    686\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 687\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattr\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\" not found\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    689\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: columns not found"
     ]
    }
   ],
   "source": [
    "train_features.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chayan\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   10.8s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   55.6s\n",
      "[Parallel(n_jobs=-1)]: Done 324 out of 324 | elapsed:  1.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best rf features -- \n",
      " RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "\n",
      "\n",
      "---------------Training Result Random Forest--------------- \n",
      " \n",
      "\n",
      "[[26  1]\n",
      " [ 9  3]]\n",
      "accuracy --  0.7435897435897436\n",
      "precision_score --  0.75\n",
      "recall_score --  0.25\n",
      "f1_score --  0.375\n",
      "classification report --- \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.96      0.84        27\n",
      "           1       0.75      0.25      0.38        12\n",
      "\n",
      "   micro avg       0.74      0.74      0.74        39\n",
      "   macro avg       0.75      0.61      0.61        39\n",
      "weighted avg       0.75      0.74      0.70        39\n",
      "\n",
      "---------------Testing Result Random Forest--------------- \n",
      " \n",
      "\n",
      "[[18  3]\n",
      " [ 6  0]]\n",
      "accuracy --  0.6666666666666666\n",
      "precision_score --  0.0\n",
      "recall_score --  0.0\n",
      "f1_score --  0.0\n",
      "classification report --- \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.86      0.80        21\n",
      "           1       0.00      0.00      0.00         6\n",
      "\n",
      "   micro avg       0.67      0.67      0.67        27\n",
      "   macro avg       0.38      0.43      0.40        27\n",
      "weighted avg       0.58      0.67      0.62        27\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Fitting 3 folds for each of 64 candidates, totalling 192 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chayan\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best svm features -- \n",
      " LinearSVC(C=0.001, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=200,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n",
      "\n",
      "\n",
      "---------------Training Result SVM--------------- \n",
      " \n",
      "\n",
      "[[27  0]\n",
      " [12  0]]\n",
      "accuracy --  0.6923076923076923\n",
      "precision_score --  0.0\n",
      "recall_score --  0.0\n",
      "f1_score --  0.0\n",
      "classification report --- \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      1.00      0.82        27\n",
      "           1       0.00      0.00      0.00        12\n",
      "\n",
      "   micro avg       0.69      0.69      0.69        39\n",
      "   macro avg       0.35      0.50      0.41        39\n",
      "weighted avg       0.48      0.69      0.57        39\n",
      "\n",
      "classification report --- \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.86      0.80        21\n",
      "           1       0.00      0.00      0.00         6\n",
      "\n",
      "   micro avg       0.67      0.67      0.67        27\n",
      "   macro avg       0.38      0.43      0.40        27\n",
      "weighted avg       0.58      0.67      0.62        27\n",
      "\n",
      "---------------Testing Result SVM--------------- \n",
      " \n",
      "\n",
      "[[21  0]\n",
      " [ 6  0]]\n",
      "accuracy --  0.7777777777777778\n",
      "precision_score --  0.0\n",
      "recall_score --  0.0\n",
      "f1_score --  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 192 out of 192 | elapsed:    0.5s finished\n",
      "C:\\Users\\Chayan\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Chayan\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Chayan\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "train(train_features, test_features,  y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction before split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work Done - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tower Name</th>\n",
       "      <th>Application Name</th>\n",
       "      <th>Email Subject</th>\n",
       "      <th>Flag</th>\n",
       "      <th>combined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Core Pharmacy</td>\n",
       "      <td>PharmRDS-Accredo RealTime Messages</td>\n",
       "      <td>Production - Accredo Real Time Order Process S...</td>\n",
       "      <td>Actionable</td>\n",
       "      <td>core pharmacy pharmrd accredo realtime message...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Core Pharmacy</td>\n",
       "      <td>IVR - Web Service</td>\n",
       "      <td>Splunk Alert: SO IVR - Pharmacy Migration Coor...</td>\n",
       "      <td>Actionable</td>\n",
       "      <td>core pharmacy ivr web service splunk alert ivr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Core Pharmacy</td>\n",
       "      <td>ISAM- Web Service</td>\n",
       "      <td>Splunk Alert: ISAM - Slowness</td>\n",
       "      <td>Actionable</td>\n",
       "      <td>core pharmacy isam web service splunk alert is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Core Pharmacy</td>\n",
       "      <td>Migration Co-Ordinaor</td>\n",
       "      <td>Splunk Alert: Migration_Coordinator_500 Clone</td>\n",
       "      <td>Actionable</td>\n",
       "      <td>core pharmacy migration ordinaor splunk alert ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Core Pharmacy</td>\n",
       "      <td>Claim Realm - Web Service</td>\n",
       "      <td>Splunk Alert: Claim Realm Service - Slowness A...</td>\n",
       "      <td>Actionable</td>\n",
       "      <td>core pharmacy claim realm web service splunk a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Tower Name                    Application Name  \\\n",
       "0  Core Pharmacy  PharmRDS-Accredo RealTime Messages   \n",
       "1  Core Pharmacy                   IVR - Web Service   \n",
       "2  Core Pharmacy                   ISAM- Web Service   \n",
       "3  Core Pharmacy               Migration Co-Ordinaor   \n",
       "4  Core Pharmacy           Claim Realm - Web Service   \n",
       "\n",
       "                                       Email Subject        Flag  \\\n",
       "0  Production - Accredo Real Time Order Process S...  Actionable   \n",
       "1  Splunk Alert: SO IVR - Pharmacy Migration Coor...  Actionable   \n",
       "2                      Splunk Alert: ISAM - Slowness  Actionable   \n",
       "3      Splunk Alert: Migration_Coordinator_500 Clone  Actionable   \n",
       "4  Splunk Alert: Claim Realm Service - Slowness A...  Actionable   \n",
       "\n",
       "                                            combined  \n",
       "0  core pharmacy pharmrd accredo realtime message...  \n",
       "1  core pharmacy ivr web service splunk alert ivr...  \n",
       "2  core pharmacy isam web service splunk alert is...  \n",
       "3  core pharmacy migration ordinaor splunk alert ...  \n",
       "4  core pharmacy claim realm web service splunk a...  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_copy[\"combined\"] = Preprocessing_lemmatization_spacy(data_copy, \"combined\")\n",
    "data_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_copy[\"combined\"]\n",
    "y = data_copy[\"Flag\"].map({\"Actionable\" : 0, \"Non Actionable\" : 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features -- \n",
      " dict_keys(['core_pharmacy', 'pharmrd', 'accredo', 'realtime', 'message', 'production', 'real', 'time', 'order', 'process', 'status', 'errore', 'ivr', 'web_service', 'splunk_alert', 'pharmacy', 'migration', 'coordinator', 'error', 'authentication', 'missing', 'isam', 'slowness', 'ordinaor', 'clone', 'claim', 'realm', 'service', 'alert', 'drugpricing', 'drug', 'pricing', 'responsestatus', 'sunday', 'nrt', 'warning', 'issue', 'iib', 'nrm', 'application', 'job', 'batch', 'abend', 'incident', 'ticket', 'number', 'esp', 'cilappxp', 'jobname', 'home_delivery', 'team_xrx', 'fatal', 'system', 'unavailable', 'team_mailrx', 'fork', 'global', 'app', 'support', 'ignio', 'ssg', 'xrx', 'health', 'check', 'fail', 'faxqd', 'log_update', 'last', 'minute', 'application_open', 'problem_failure', 'rate_increase', 'chc_xrx', 'prod', 'chdpxrxtransactionservicewshpv', 'report', 'generation', 'endo', 'hub', 'shipment', 'mwf', 'fri', 'processing', 'exception', 'move', 'forward', 'cauth', 'please', 'reach', 'business', 'require', 'iis', 'image', 'viewer', 'saturday', 'perfmon', 'net', 'clr', 'memory', 'create', 'techrx', 'file', 'size', 'problem', 'eof', 'mailrx', 'router', 'log', 'chdpxrxtransacionservicewshttpv', 'team', 'fairfax', 'workflowapp', 'ansi', 'esi', 'response', 'trk', 'num', 'container', 'empty', 'explorer', 'apm', 'cilsysmp', 'chdp', 'current', 'qdepth', 'danger', 'state', 'srwsqlxpw', 'internal', 'cigna', 'notify', 'major', 'soi', 'cache', 'manager', 'load', 'lock', 'count', 'wdc', 'fairfx', 'qpopulate', 'las', 'mins', 'weekday', 'clinicla_cmg', 'cerner', 'ceweblink', 'connection', 'find', 'celvr', 'port', 'respond', 'allscript', 'critical', 'ciwiis', 'lgenl', 'windows', 'twcssspooler', 'run', 'allscripts_critical', 'ciwinp', 'low', 'hard', 'drive', 'space', 'available', 'warn', 'ciwsqlxp_lmsdb', 'back', 'database', 'chmedispan', 'ciwsqlxp', 'cigwork', 'ltwdb', 'print', 'queue', 'critically', 'high', 'follow', 'value', 'dental', 'send', 'fiserv', 'finish', 'fsrload', 'blockers', 'webprd', 'easton', 'ohip', 'welcome', 'letter', 'mail', 'date', 'miss', 'pdf', 'success', 'extract', 'dat', 'mmmb', 'request', 'need', 'attn', 'action', 'mgmi', 'etl', 'tmp', 'cbor', 'npi', 'validation', 'oracle', 'conversion', 'payment', 'spreadsheet', 'mnmi', 'abort', 'mnmb', 'dna', 'prd', 'subject_contain', 'failure_word', 'rds', 'coresol', 'ffvrd', 'ods', 'pdm', 'mart', 'pda', 'qvc', 'kafka', 'connector'])\n"
     ]
    }
   ],
   "source": [
    "train_features,_ = feature_extraction_3(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_features, y, test_size=0.40, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chayan\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   16.5s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 324 out of 324 | elapsed:  1.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best rf features -- \n",
      " RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='gini', max_depth=2, max_features='auto',\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=200, n_jobs=None, oob_score=False,\n",
      "            random_state=None, verbose=0, warm_start=False)\n",
      "\n",
      "\n",
      "---------------Training Result Random Forest--------------- \n",
      " \n",
      "\n",
      "[[27  0]\n",
      " [12  0]]\n",
      "accuracy --  0.6923076923076923\n",
      "precision_score --  0.0\n",
      "recall_score --  0.0\n",
      "f1_score --  0.0\n",
      "classification report --- \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      1.00      0.82        27\n",
      "           1       0.00      0.00      0.00        12\n",
      "\n",
      "   micro avg       0.69      0.69      0.69        39\n",
      "   macro avg       0.35      0.50      0.41        39\n",
      "weighted avg       0.48      0.69      0.57        39\n",
      "\n",
      "---------------Testing Result Random Forest--------------- \n",
      " \n",
      "\n",
      "[[21  0]\n",
      " [ 6  0]]\n",
      "accuracy --  0.7777777777777778\n",
      "precision_score --  0.0\n",
      "recall_score --  0.0\n",
      "f1_score --  0.0\n",
      "classification report --- \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.88        21\n",
      "           1       0.00      0.00      0.00         6\n",
      "\n",
      "   micro avg       0.78      0.78      0.78        27\n",
      "   macro avg       0.39      0.50      0.44        27\n",
      "weighted avg       0.60      0.78      0.68        27\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Fitting 3 folds for each of 64 candidates, totalling 192 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chayan\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Chayan\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Chayan\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Chayan\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Chayan\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Chayan\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Chayan\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best svm features -- \n",
      " LinearSVC(C=0.001, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=200,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n",
      "\n",
      "\n",
      "---------------Training Result SVM--------------- \n",
      " \n",
      "\n",
      "[[27  0]\n",
      " [12  0]]\n",
      "accuracy --  0.6923076923076923\n",
      "precision_score --  0.0\n",
      "recall_score --  0.0\n",
      "f1_score --  0.0\n",
      "classification report --- \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      1.00      0.82        27\n",
      "           1       0.00      0.00      0.00        12\n",
      "\n",
      "   micro avg       0.69      0.69      0.69        39\n",
      "   macro avg       0.35      0.50      0.41        39\n",
      "weighted avg       0.48      0.69      0.57        39\n",
      "\n",
      "classification report --- \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.88        21\n",
      "           1       0.00      0.00      0.00         6\n",
      "\n",
      "   micro avg       0.78      0.78      0.78        27\n",
      "   macro avg       0.39      0.50      0.44        27\n",
      "weighted avg       0.60      0.78      0.68        27\n",
      "\n",
      "---------------Testing Result SVM--------------- \n",
      " \n",
      "\n",
      "[[21  0]\n",
      " [ 6  0]]\n",
      "accuracy --  0.7777777777777778\n",
      "precision_score --  0.0\n",
      "recall_score --  0.0\n",
      "f1_score --  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 192 out of 192 | elapsed:    1.0s finished\n",
      "C:\\Users\\Chayan\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Chayan\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Chayan\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Chayan\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Chayan\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Chayan\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "train(X_train, X_test,  y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
